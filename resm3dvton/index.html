<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Res-M3D-VTON</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Monocular-to-3D Virtual Try-On using Deep Residual U-Net</span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<!--Add author names here.-->
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="http://hasibzunair.github.io/">Hasib Zunair</a><sup>1</sup></span>
						</center>
					</td>
					
					<!--
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://en.wikipedia.org/wiki/James_J._Gibson">Second Author</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://en.wikipedia.org/wiki/James_J._Gibson">Third Author</a></span>
						</center>
					</td>
					-->
				</tr>
			</table>

			<!--Add affiliations here.-->
			<table align="center" width="700px">
			   <tbody><tr>
				<td align="center" width="200px">
				<center>
				  <span style="font-size:20px"><sup>1</sup>Concordia University, Montreal, QC, Canada.</span>
				</center>

				<!--
				</td>
				  <td align="center" width="200px">
				<center>
				  <span style="font-size:20px"><sup>2</sup>University X</span>
				</center>
				-->
				</td>
			 </tr>
			</tbody></table>

			
			<!--Add publication details here.-->
			<br>
			<table align="center" width="700px">
			<tbody><tr>
				<td align="center" width="100px">
				<center>
				<span style="font-size:20px; color:red;">COMP 6381, Fall 2021</span>
				</center>
				<center>
				<span style="font-size:20px">Digital Geometric Modelling</span>
				</center>
				</td>
			</tr>
			</tbody></table>
			
			<!--Add supplementary links here.-->
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/hasibzunair/res-m3d-vton'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<!--Add intro image here.-->
						<img class="round" style="width:850px" src="./resources/combined1.gif"/>
						<img class="round" style="width:850px" src="./resources/combined2.gif"/>
					</center>
				</td>
			</tr>
			
			<!--For figure caption.
			<img class="round" style="width:800px" src="./resources/vis_3d.png"/>
			-->
			
			<tr><td width="600px">
			<center>
				<span style="font-size:14px"><i>Here are some results of our method on out-of-distribution images. Given the <strong>reference person image</strong>
					(left) and <strong>target clothing image</strong> (middle), our method can reconstruct the <strong>3D try-on mesh</strong> (right) with the clothing changed 
					 and person identity retained.
				</i>
			</span></center>
			</td>
			</tr>
			</tbody></table>

		</table>
		<table align=center width=850px>
			<tr>
				<td><br>
					<strong>TL;DR:</strong> Res-M3D-VTON is a pipeline for monocular to 3D virtual try-on (VTON) for 
					fashion clothing which addresses the limitations of exisiting state-of-the-art 3D VTON approaches.</a>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Virtual 3D virtual try-on aims to synthetically fit a target clothing image onto a 3D human shape 
				while preserving realistic details such as pose, identity of the person. Existing methods heavily depend on 
				annotated 3D shapes and garment templates 
				which limits their practical use. While 2D virtual try-on is another alternative, it ignores the 3D body 
				information and cannot fully represent the human body. Recently, <a href='https://arxiv.org/abs/2108.05126'>M3D-VTON</a> 
				was proposed to generate 
				textured 3D try-on meshes only from 2D images of person and clothing by formulating the 3D try-on problem
				as 2D try-on and depth estimation. However, we find that the synthesis model in the M3D-VTON pipeline 
				uses a simple U-Net architecture. We hypothesize that this is insufficient to synthesize body parts 
				and differentiate between front and back parts of clothing only from the 2D image, 
				ultimately leading to unrealistic 3D try-on results. We improve this by 
				implementing residual units in the existing synthesis model. Studying itâ€™s effect demonstrates that 
				it improves 2D try-on outputs, mainly by <FONT COLOR="#46C646">differentiating between front and back part of clothing</FONT>, 
				<FONT COLOR="#46C646">preserving logo of clothing</FONT> and <FONT COLOR="#46C646">reducing artifacts</FONT>. 
				This ultimately results in better textured 
				3D try-on mesh. Benchmarking our method on the MPV3D dataset shows that it performs better than 
				previous works significantly.
				<p></p>
				<img class="round" style="width:800px" src="./resources/vis_3d.png"/>
			</td>
		</tr>

		<tr><td width="600px">
			<center>
				<span style="font-size:14px"><i>Comparison of 2D and 3D try-on mesh outputs with recent state-of-the-art 
					<a href='https://arxiv.org/abs/2108.05126'>M3D-VTON</a>.
				</i>
			</span></center>
			</td>
		</tr>

	</table>
	<hr>
	<br>

	<!--Add YouTube talk here.-->
	<!--
	<center><h1>Talk</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
	</p>

	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href=''>[Slides]</a>
				</span>
			</center>
		</tr>
	</table>
	<hr>
	-->

	<!--Add demo code here with architecture.-->
	<center><h1>Method</h1></center>
	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:1000px" src="./resources/model.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<strong>Overview of the proposed framework</strong>. Left image taken from <a href='https://arxiv.org/abs/2108.05126'>M3D-VTON paper</a>.
					Add more details here.
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/hasibzunair/res-m3d-vton#running-on-custom-images'>[GitHub]</a> Demo
			</center>
		</span>
	</table>
	<br>
	<hr>

		<center><h1>Extensive results for 2D virtual try-on</h1></center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<!--Add intro image here.-->
						<img class="round" style="width:800px" src="./resources/visualization_tryons_all.png"/>
					</center>
				</td>
			</tr>
			<!--For figure caption.-->

			<tr><td width="600px">
			<center>
				<span style="font-size:14px"><i>Visual comparison of 2D try-on outputs with <a href='https://arxiv.org/abs/2108.05126'>M3D-VTON</a>.</i>
			</span></center>
			</td>
			</tr>
			</tbody></table>

		</table>
		<table align=center width=850px>
			<tr>
				<td>
					Here we show some examples of the final try-on outputs compared to previous work. 
					In many cases, we see that the baseline model is unable to <FONT COLOR="#ff0000">differentiate between the
					front and back of clothing</FONT>. It also tends to <FONT COLOR="#ff0000">change the skin color of the person</FONT>. 
					The baseline model also <FONT COLOR="#ff0000">fails to preserve the logo of clothing image</FONT>. This is due 
					to the limited capability of the U-Net architecture employed in the baseline model. In comparison, 
					the proposed method generates realistic try-on results which <strong>differentiates front and 
					back part of clothing</strong>, <strong> preserve logo of clothing</strong>. It also <strong>reduces 
					artifacts</strong> in non-target body parts such as skin.
</a>
				</td>
			</tr>
		</table>
		<br>
		<hr>


	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">H. Zunair<br>
				<b>Monocular-to-3D Virtual Try-On using Deep Residual U-Net.</b><br>
				COMP 6321 Digital Geometric Modelling Course Project, Fall 2021.<br>
				<!--Add arXiv link-->
				<!--(hosted on <a href="">ArXiv</a>)<br> -->
				<!--Add camera ready link-->
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<!--Add Bibtex-->
	<!--
	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>
	-->
	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					We thank <a href="https://users.encs.concordia.ca/~stpopa/">Dr. Tiberiu Popa</a> for useful discussions during the development of this project. 
					We also thank Concordia University and Compute Canada for providing computational resources and support that contributed to these research results.
					Some of the computing for this project was performed on the Graham cluster. This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

