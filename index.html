<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=‚Äúwidth=800‚Äù>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    position: relative;
    }
    .two
    {
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  
<!--
  width: 0;
  height: 0;
-->

  <title>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="my_icon.png">
  </head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</name>
        </p>
        <p>
          I got a Ph.D from <a href="https://www.concordia.ca/">Concordia University</a>, where I worked on 
          efficient contextual representation learning techniques for computer vision applications. I also built end-to-end machine learning systems for sport use-cases at <a href="https://www.decathlon.ca/en/">D√©cathlon</a> and 
          taught machine learning at <a href="https://www.ericsson.com/en">Ericsson</a>. üß†
        </p>

        <p>
          Previously, I did a two-year internship at Decathlon working on <a href="https://arxiv.org/abs/2210.00918">generative AI virtual try-on</a> and <a href="https://arxiv.org/abs/2108.08362">semi-supervised learning</a>. 
          And before that, I got a MASc at Concordia, where I worked on 
          <a href="https://spectrum.library.concordia.ca/id/eprint/988565/2/Zunair_MASc_S2021.pdf">medical image analysis</a>. üëÄ          
        </p>

        <p>
          In my free time, I read books, cook fancy meals, lift heavy weights and spend time in nature. üåø
        </p> 

        <p><font color="red"> <strong>I'm currently looking for industry roles in computer vision.</strong></font> 

        <p align=center>
          <a href="mailto:hasibzunair@gmail.com">Email</a> &nbsp/&nbsp
          <!-- <a href="data/Hasib_Zunair_CV.pdf"> CV </a> &nbsp/&nbsp -->
          <a href="https://www.linkedin.com/in/hasibzunair/"> LinkedIn </a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=A_0zJN0AAAAJ&hl=en">Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/hasibzunair">GitHub</a> &nbsp/&nbsp
          <a href="https://twitter.com/hasibzunair"> Twitter</a>
        </p>
        </td>
        <td style="padding:0;width:50%;max-width:50%">
        <a href="hasib_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="hasib_circle.png"></a>
        </td>
      </tr>
      </table>

    <hr>
    

    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Bio</heading>  
          <p>
            I am an AI researcher and engineer, specializing in <strong>computer vision</strong> and 
            <strong>machine/deep learning</strong>, with over 5 years of experience in both academia and industry. üî¨
          </p>
          
          <p>
            My goal is to build and democratize AI systems that learn with less data, compute and better understand the visual world around us. 
            I am working to identify and overcome challenges in deploying computer vision tools, driven by their real-world potential, 
            from self-driving cars, to assistive technologies, to healthcare. Specifically focussing on <strong>visual perception and generation</strong>, 
            <strong>representation learning</strong>, and <strong>generalization</strong>. ü§ñ
          </p>

          <p>
            I have created AI tools addressing complex real-world challenges in computer vision, for example, occlusions, small objects and data imbalance. 
            I have several lead-author publications at top venues like <strong>WACV</strong>, <strong>BMVC</strong>, <strong>ICIP</strong> and <strong>IEEE TMI</strong>, and received awards like the 
            <strong>MITACS Accelerate Fellowship</strong>. 
            I've also built production-grade ML/CV solutions, from framing to deployment on cloud and on edge compute. I helped 
            companies improve accuracy and efficiency of systems, increase user engagement, develop skills, cut costs, save time and resources. üè≠
          </p>

          <p>
            Besides, I <strong>contribute to open-source software</strong> in top deep learning libraries like <a href="https://keras.io/examples/vision/3D_image_classification/">TensorFlow</a>, <a href="https://github.com/kornia/kornia/pull/1551">Kornia</a> & <a href="https://github.com/meituan/YOLOv6/pull/685?fbclid=IwAR332dEHvp773_JFE41s8sszEJSJTBUtXssE9R1uvtpcXWkw9tn8PROsMIg">YOLOv6</a>, 
            runners up in <strong>ML competitions</strong> like <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">ImageCLEF Medical</a> and <a href="https://github.com/hasibzunair/automated-retail-checkout-aicity22">AICITY at CVPR</a>, and  <strong>mentor</strong> numerous AI practitioners. 
            I constantly <strong>learn</strong> to stay current in the field, and share them through <a href="https://hasibzunair.medium.com/"><strong>writing articles</strong></a> and 
            <a href="https://www.youtube.com/@hasibzunair"><strong>creating videos</strong></a> to help others grow. üßë‚Äçüè´
          </p>
          
          <p>
            I try to practice <a href="http://slow-science.org/">Slow Science</a>.
          </p>
        
        </td>
      </tr>
      </table>
      
      <hr>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
            See also my Google Scholar profile for the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works&sortby=pubdate"> most recent publications</a> as well 
            as the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works">most-cited papers</a>.
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bmvc2024-peekaboo.png'></div>
            <img src='bmvc2024-peekaboo.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2407.17628">
          <papertitle>PEEKABOO: Hiding Parts of an Image for Unsupervised Object Localization</papertitle></a><br>
          <strong>Hasib Zunair</strong>, A. Ben Hamza<br>
          <em>British Machine Vision Conference</em>, 2024<br>
          <a href="https://arxiv.org/abs/2407.17628">Paper</a> / 
          <a href="https://github.com/hasibzunair/peekaboo">Code</a> /
          <a href="https://hasibzunair.github.io/peekaboo/">Website</a>
          <p>
            A segmentation model with zero-shot generalization to unfamiliar images and objects that 
            are small, reflective or under poor illumination without the need for additional training.
          </p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='rsud20k_icip.png'></div>
            <img src='rsud20k_icip.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2401.07322">
          <papertitle>RSUD20K: A Dataset for Road Scene Understanding In Autonomous Driving</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Shakib Khan, A. Ben Hamza<br>
          <em>IEEE International Conference on Image Processing</em>, 2024 <font color="red">(Oral Presentation)</font></a><br>
          <a href="https://arxiv.org/abs/2401.07322">Paper</a> / 
          <a href="https://github.com/hasibzunair/RSUD20K">Code</a> /
          <a href="https://huggingface.co/spaces/Shakib-IO/RSUD20K_DEMO">Demo</a>
          <p>
            A dataset with 20K high-resolution images and 130K bounding box annotations. Benchmark object detectors 
            and explore large vision language models (LVLMs) as image annotators.
          </p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='wacv2024-msl.png'></div>
            <img src='wacv2024-msl.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2310.18517">
          <papertitle>Learning to Recognize Occluded and Small Objects with Partial Inputs</papertitle></a><br>
          <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2024<br>
          <a href="https://arxiv.org/abs/2310.18517">Paper</a> / 
          <a href="https://github.com/hasibzunair/msl-recognition">Code</a> /
          <a href="https://hasibzunair.github.io/msl-recognition/">Website</a>
          <p>
            Using masking to focus on context from neighbouring regions around objects and learn a distribution of association across classes, 
            to better recognize occluded and small objects.
          </p>
        </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='arxiv2023-cosif.png'></div>
            <img src='arxiv2023-cosif.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/pii/S0010482524004013">
          <papertitle>CosSIF: Cosine similarity-based image filtering to overcome low inter-class variation in synthetic medical image datasets</papertitle></a><br>
          Mominul Islam, <strong>Hasib Zunair</strong>, Nabeel Mohammed<br> 
          <em>Computers in Biology and Medicine</em>, 2024<br>
          <a href="https://arxiv.org/abs/2307.13842">Paper</a> / 
          <a href="https://github.com/mominul-ssv/cossif">Code</a>
          <p>
            Data filtering algorithm based on cosine similarity to remove similar and redundant synthetic images from the 
            minority class that resemble similarity to images from the majority class.
          </p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bmvc2022-masksup.png'></div>
            <img src='bmvc2022-masksup.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2210.00923">
          <papertitle>Masked Supervised Learning for Semantic Segmentation</papertitle></a><br>
          <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>British Machine Vision Conference</em>, 2022 <font color="red">(Oral Presentation)</font></a><br>
          <a href="https://arxiv.org/abs/2210.00923">Paper</a> / 
          <a href="https://github.com/hasibzunair/masksup-segmentation">Code</a> /
          <a href="https://bmvc2022.mpi-inf.mpg.de/0417_poster.pdf">Poster</a> / 
          <a href="https://bmvc2022.mpi-inf.mpg.de/0417_video.mp4">Video</a> 
            <p>
              A single-stage method that captures the contextual relationships between 
              pixels via masking, shows good segmentation performance, especially in 
              ambiguous regions and minority classes.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bmvc2022-fifa.png'></div>
            <img src='bmvc2022-fifa.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2210.00918">
          <papertitle>Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based Virtual Try-On</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Samuel Mercier, Yan Gobeil, A. Ben Hamza<br> 
          <em>British Machine Vision Conference</em>, 2022<br>
          <a href="https://arxiv.org/abs/2210.00918">Paper</a> / 
          <a href="https://github.com/hasibzunair/fifa-tryon">Code</a> /
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_poster.pdf">Poster</a> / 
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_video.mp4">Video</a>
          <p>
            A self-supervised generative adversarial network based framework
            for virtual try-on to handle complex person poses while retaining the texture and embroidery of clothing items.
          </p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cimb2022_leuk.png'></div>
            <img src='cimb2022_leuk.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522010800">
          <papertitle>Quantifying imbalanced classification methods for leukemia detection</papertitle></a><br>
          Deponker SarkerDepto, Md. Mashfiq Rizvee, Aimon Rahman, <strong>Hasib Zunair</strong>, M. Sohel Rahman, M.R.C. Mahdy<br> 
          <em>Computers in Biology and Medicine</em>, 2022<br>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522010800">Paper</a> / 
          <a href="https://github.com/Deponker/imbalanced_classification_leukemia">Code</a> 
            <p>
              We benchmark several methods designed to tackle class imbalance and find that loss-based methods 
              outperform GAN-based and input-based methods for leukemia detection.
            </p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='vista_cvprw2022.png'></div>
            <img src='vista_cvprw2022.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2204.11024">
          <papertitle>VISTA: Vision Transformer enhanced by U-Net and Image Colorfulness Frame Filtration for Automatic Retail Checkout</papertitle></a><br>
          Md. Istiak Hossain Shihab, Nazia Tasnim, <strong>Hasib Zunair</strong>, Labiba Kanij Rupty, Nabeel Mohammed<br>
          <em>IEEE/CVF Computer Vision and Pattern Recognition Workshop</em>, 2022<br>
          <a href="https://arxiv.org/abs/2204.11024">Paper</a> / 
          <a href="https://github.com/istiakshihab/automated-retail-checkout-aicity22">Code</a> /
          <a href="https://drive.google.com/file/d/14eXT3ek6xCs7UU4lQ-lyeNS80f0Oqpat/view?usp=sharing">Slides</a> /
          <a href="https://github.com/NVIDIAAICITYCHALLENGE/2022AICITY_Code_From_Top_Teams/">Leaderboard <font color="red">(3rd place)</font></a>
            <p>
              A segmenter (U-Net) followed by a Vision Transformer (ViT) classifier for recognizing product items from videos. 
              Our method achieved 3rd place in the <a href="https://www.aicitychallenge.org/2022-data-and-evaluation/"> AI City Challenge, Track 4</a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cibm2022.png'></div>
            <img src='cibm2022.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522003730?via%3Dihub">
          <papertitle>Knowledge distillation approach towards melanoma detection</papertitle></a><br>
          Md Shakib Khan, Kazi Nabiul Istla, Abdur Rab Dhruba, <strong>Hasib Zunair</strong>, Nabeel Mohammed<br> 
          <em>Computers in Biology and Medicine</em>, 2022<br>
          </p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522003730?via%3Dihub">Paper</a> / 
          <a href="https://github.com/Shakib-IO/KD-lesions">Code</a> 

            <p>
              A knowledge distillation appraoch for melanoma detection to reduce model complexitiy and enable easy deployment in edge devices.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cu_thesis.jpg'></div>
            <img src='cu_thesis.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://spectrum.library.concordia.ca/id/eprint/988565/2/Zunair_MASc_S2021.pdf">
          <papertitle>Designing Efficient Deep Learning Models for Computer-Aided Medical Diagnosis</papertitle></a><br>
          <strong>Hasib Zunair</strong> <br>
          <em>Masters Thesis</em>, 2021<br>
          <a href="https://spectrum.library.concordia.ca/id/eprint/988565/">Paper</a> / 
          <a href="https://github.com/hasibzunair/masters-thesis-projects">Code</a>
          <p>
            Introduces various efficient deep learning architectures and generative modeling methods to 
            address the scarcity of labels as well as class imbalance in biomedical image analysis.
            </p>
        </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='sharpunet.png'></div>
            <img src='sharpunet.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004935">
          <papertitle>Sharp U-Net: Depthwise convolutional network for biomedical image segmentation</papertitle></a><br>
          <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>Computers in Biology and Medicine</em>, 2021<br>
          <a href="https://arxiv.org/abs/2107.12461">Paper</a> / 
          <a href="https://github.com/hasibzunair/sharp-unets">Code</a> 

            <p>
              We propose to fuse encoder and decoder features in U-Nets using a sharpening kernel filter leading to improved 
              performance on various medical image segmentation tasks.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='star_mmsports.png'></div>
            <img src='star_mmsports.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://dl.acm.org/doi/10.1145/3475722.3482791">
          <papertitle>STAR: Noisy Semi-Supervised Transfer Learning for Visual Classification</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Yan Gobeil, Samuel Mercier, A. Ben Hamza <br> 
          <em>International ACM Workshop on Multimedia Content Analysis in Sports</em>, 2021 <br>
          
          <a href="https://arxiv.org/abs/2108.08362">Paper</a> / 
          <a href="https://github.com/Decathlon/decavision">Code</a> /
          <a href="https://medium.com/decathlontechnology/improving-performance-of-image-classification-models-using-pretraining-and-a-combination-of-e271c96808d2">Blog Post</a> /
          <a href="https://drive.google.com/drive/folders/178j1L8wivD5h1q3wkfs0XbXPNpf2LdyS">Video</a>
          
            <p>
              An efficient and robust semi-supervised learning method for image classification.
              It requires 6x less compute time and 5x less memory compared to prior arts.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>
      

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='clef2021.png'></div>
            <img src='clef2021.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="http://ceur-ws.org/Vol-2936/paper-121.pdf">
          <papertitle>ViPTT-Net: Video pretraining of spatio-temporal model for tuberculosis type classification from chest CT scans</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Aimon Rahman, and Nabeel Mohammed<br> 
          <em>Conference and Labs of the Evaluation Forum</em>, 2021<br>

          <a href="https://arxiv.org/abs/2105.12810">Paper</a> / 
          <a href="https://github.com/hasibzunair/viptt-net">Code</a> /
          <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard <font color="red">(2nd place)</font></a>

            <p> Pretraining on videos for human activity recognition leads to better learning for 
              tuberculosis type classification. This method was 2nd place in 
              the <a href="https://www.imageclef.org/2021/medical/tuberculosis"> ImageCLEF 2021 Medical.</a></p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ISBI-MoNuSAC2020.png'></div>
            <img src='ISBI-MoNuSAC2020.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://ieeexplore.ieee.org/document/9446924">
          <papertitle>MoNuSAC2020: A Multi-organ Nuclei
            Segmentation and Classification Challenge</papertitle></a><br>
          Ruchika Verma, Neeraj Kumar, <strong> Hasib Zunair</strong>, A. Ben Hamza and others.<br> 
          <em>IEEE Transactions on Medical Imaging</em>, 2021 <br>
          <a href="https://ieeexplore.ieee.org/document/9446924">Paper </a> / 
          <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code </a> / 
          <a href="https://docs.google.com/presentation/d/11ym6YdXazpAhkqH348X8fyHmZEoLd81xozrPHAJko44/edit?usp=sharing">Slides</a> / <a href="https://youtu.be/QztsH4IYQRA">Video (Time - 1:58:46)</a> /
          <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard </a> <font color="red">(11th place)</font>
          
          <p>
              This paper summarizes and publicly releases the challenge dataset, and compile key findings of the 
              methods developed by various participants.
            </p>
          </td>
        </tr>
        </table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='covid.png'></div>
            <img src='covid.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
	  <p><a href="https://link.springer.com/article/10.1007/s13278-021-00731-5">
          <papertitle>Synthesis of COVID-19 Chest X-rays using Unpaired Image-to-Image Translation</papertitle></a><br>
          <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>International Conference on Machine Learning Workshop</em>, 2021 <br>
          <em>Social Network Analysis and Mining</em>, 2021 <br>
          <a href="https://arxiv.org/abs/2010.10266">Paper</a> / 
          <a href="https://arxiv.org/abs/2106.09759">ICML Workshop Ext. Abstract</a> /
          <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset</a>
           
            <p> 
              Generate synthetic image data by class conditioning and adversarial training to use as additional training data 
              for imbalanced image classification.
             </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell2.png' width="160"></div>
            <img src='tissueandcell2.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">
          <papertitle>Automatic segmentation of blood cells from microscopic slides: A comparative analysis</papertitle></a><br>
          Deponker Sarker Depto, Shazidur Rahman, Md. Mekayel Hosen, Mst Shapna Akter, 
          Tamanna Rahman Reme, Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021 <br>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">Paper</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation-dataset">Dataset</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation">Code</a>
           
            <p>
              A blood cell segmentation dataset consisting of multiple cell types and benchmark of 
              both learning and non-learning based methods.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell.png' width="160"></div>
            <img src='tissueandcell.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub">
          <papertitle>A Comparative Analysis of Deep Learning Architectures on High Variation Malaria Parasite Classification Dataset</papertitle></a><br>
          Aimon Rahman, <strong>Hasib Zunair</strong>, Tamanna Rahman Reme, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021 <br>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub6">Paper</a>
           
            <p>
              Transform a high variation malaria localization dataset to classification and benchmark several 
              classification algorithm for malaria identification from microscopic images of red blood cells.</p>
            <p></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='PRIME-MICCAI2020.jpg' width="160"></div>
            <img src='PRIME-MICCAI2020.jpg' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://link.springer.com/chapter/10.1007%2F978-3-030-59354-4_15">
          <papertitle>Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed, and Joseph Paul Cohen<br> 
          <em>International Conference on Medical Image Computing and Computer Assisted Intervention Workshop</em>, 2020<br>
          <a href="https://arxiv.org/abs/2007.13224">Paper</a> / 
          <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> /
          <a href="https://youtu.be/IP6poudyny4">Video</a>
          <p>Analyzing 3D medical images in a per slice basis is a sub-optimal approach, that can be improved by 3D context. 
            The method was ranked 5th in <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF Medical 2019</a>.</p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='MelaNet-PMB.jpg'></div>
            <img src='MelaNet-PMB.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://iopscience.iop.org/article/10.1088/1361-6560/ab86d3">
          <papertitle>Melanoma Detection using Adversarial Training and Deep Transfer Learning</papertitle></a><br>
          <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>Physics in Medicine and Biology</em>, 2020<br>
          <a href="https://arxiv.org/abs/2004.06824">Paper</a> / <a href="https://github.com/hasibzunair/adversarial-lesions">Code</a>
           
            <p>
              Improving fairness of medical classifiers and reduce data imbalance by enriching training datasets by generating synthetic 
              under-represented class samples from over-represented ones.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='robust-dsr-AppSci.png'></div>
              <img src='robust-dsr-AppSci.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p><a href="https://www.mdpi.com/2076-3417/10/21/7522?fbclid=IwAR14F6l9F8UKvhReG273_ZLl5YnWKUuRAu4INNP1uNGfxhAWrdlipnN9Yd8">
            <papertitle>Robust Deep Speaker Recognition: Learning Latent Representation with Joint Angular Margin Loss</papertitle></a><br>
            Labib Chowdhury, <strong>Hasib Zunair</strong> and Nabeel Mohammed<br>
            <em>Applied Sciences</em>, 2020 <br>
            <a href="https://www.mdpi.com/2076-3417/10/21/7522/htm">Paper</a> / <a href="https://github.com/jongli747/robust-dsr">Code</a></a>
  
              <p>SincNet models consistently outperform prior models and generalizes well on unseen and diverse tasks such as Bengali speaker recognition.</p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='malariadetection2019.png'></div>
          <img src='malariadetection2019.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1907.10418">
        <papertitle>Improving Malaria Parasite Detection from Red Blood Cell using Deep Convolutional Neural Networks</papertitle></a><br>
        Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, Jesia Quader Yuki, Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy<br> 
        <em>arXiv</em>, 2019 <br>
        <a href="https://arxiv.org/abs/1907.10418">Paper</a> / <a href="https://github.com/hasibzunair/malaria-detection">Code</a>            
          <p>Benchmark several classification algorithms for malaria detection from microscopic images of red blood cells.</p>
          </a></p>
        </td>
        </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='imageclef2019.jpg'></div>
            <img src='imageclef2019.jpg'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
        <td valign="top" width="75%">
            <p><a href="http://www.dei.unipd.it/~ferro/CLEF-WN-Drafts/CLEF2019/paper_77.pdf">
              <papertitle>Estimating Severity from CT Scans of Tuberculosis Patients using 3D Convolutional Nets</papertitle></a><br>
              <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed<br>
              <em>Conference and Labs of the Evaluation Forum</em>, 2019 <br>
          <a href="https://www.researchgate.net/publication/334680379_Estimating_Severity_from_CT_Scans_of_Tuberculosis_Patients_using_3D_Convolutional_Nets_and_Slice_Selection">Paper</a> / <a href="https://github.com/hasibzunair/tuberculosis-severity">Code</a>
          <p></p>
          <p>A 3D CNN with a slice selection method to predict tuberculosis (TB) from chest CT images. Our method achieved 10-th place in the <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019
              Medical</a>.
          </p>
          </td>
          </tr>
          </table>

    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"> 
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='unconventionalwisdom2018.png'></div>
          <img src='unconventionalwisdom2018.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8554435">
        <papertitle>Unconventional Wisdom: A New Transfer Learning Approach Applied to Bengali Numeral Classification</papertitle></a><br>
       <strong>Hasib Zunair</strong>, Nabeel Mohammed, Sifat Momen<br> 
        <em>International Conference on Bangla Speech and Language Processing</em>, 2018<br>
          <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/kaggle_numtaDB">Code</a>
         
          <p>A deep transfer learning approach that freezes intermediate layers for better accuracy on 
            the NumtaDB Bengali handwritten digit dataset. </p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
     <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='web-attendance.png'></div>
          <img src='web-attendance.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535928">
        <papertitle>Design and Implementation of an Automated Web Based Multifunctional Attendance System</papertitle></a><br>
        <strong>Hasib Zunair</strong>, Oishi Maniha, Jubayer Kabir<br> 
        <em>International Conference on Smart Sensors and Applications</em>, 2018 <font color="red">(Best Student Paper)</font> <br>
          <a href="https://www.researchgate.net/publication/327668463_Design_and_Implementation_of_an_Automated_Multi-Functional_Attendance_System_with_Real_Time_Web_Visualization">Paper</a> / <a href="https://drive.google.com/open?id=1-TZIqdn-yAMrQZzFy0vFnX2vNpStaBKK">Slides</a>
          <p>Implementation of an automated multifunctional attendance system which uses rfid, fingerprint, and real time facial recognition.</p>
          </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='IOT-Vessels.png'></div>
          <img src='IOT-Vessels.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535976">
        <papertitle>Design and Implementation of an IOT based Monitoring System for Inland Vessels using Multiple Sensor Network</papertitle></a><br>
        <strong>Hasib Zunair</strong>, Wordh Ul Hasan, Kimia Tuz Zaman, Irfanul Haque, Soumic Shekhar Aoyon<br>
        <em>International Conference on Smart Sensors and Applications</em>, 2018 <br>
          <a href="https://www.researchgate.net/publication/324173874_Design_and_Implementation_of_an_IoT_Based_Monitoring_System_for_Inland_Vessels_Using_Multiple_Sensors_Network">Paper</a> / <a href="https://drive.google.com/open?id=1pQc4Q5gT4CLA_1_DUx2Ln04lcYBeDR2q">Slides</a>
          <p>A wireless sensor network with a real time web application for monitoring multiple ships to prevent catastrophic events due to 
            overloading.</p>
          </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='ams2017.png'></div>
          <img src='ams2017.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8424310/">
        <papertitle>Design and Implementation of Security Patrol Robot using Android Application</papertitle></a><br>
        Tahzib Mashrik, <strong> Hasib Zunair</strong>, Maofic Farhan Karin<br> 
        <em>Asia Modelling Symposium</em>, 2017<br>
        <a href="https://www.researchgate.net/publication/323695337_Design_and_Implementation_of_Security_Patrol_Robot_using_Android_Application">Paper</a>
        <p>A low-cost autonomous mobile security robot based on a multisensor system for the purpose of sending alarms remotely. </p>
        </td>
      </tr>
    </table>

      <br>
      <hr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Machine Learning Competitions</heading>
            <p></p>
            <p><i>Product Counting and Recognition for Retail Checkout</i>, AI City Challenge, CVPR Workshop, 2022 (<font color="red">3rd Place</font>) <br>
              <a href="https://arxiv.org/abs/2204.11024">Paper</a> / <a href="https://github.com/istiakshihab/automated-retail-checkout-aicity22">Code</a> / <a href="https://github.com/NVIDIAAICITYCHALLENGE/2022AICITY_Code_From_Top_Teams/#track-4-multi-class-product-counting--recognition-for-automated-retail-checkout">Leaderboard</a></p>
  
              <p><i>Tuberculosis Type Classification from 3D CT Scans</i>, ImageCLEF, 2021 (<font color="red">2nd Place</font>) <br>
                <a href="https://arxiv.org/abs/2105.12810">Paper</a> / <a href="https://github.com/hasibzunair/viptt-net">Code</a> / <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard</a></p>
  
              <p><i>Nuclei Segmentation and Classification from Whole Slide Images</i>, MoNuSAC, 2020 (<font color="red">11th Place</font>) <br>
                <a href="https://www.researchgate.net/profile/Ruchika-Verma-3/publication/352228330_L11_Patch_Efficient_Convolutional_Network_for_Multi-Organ_Nuclei_Segmentation_and_Classification/links/60c011c4a6fdcc512815fac6/L11-Patch-Efficient-Convolutional-Network-for-Multi-Organ-Nuclei-Segmentation-and-Classification.pdf">Paper</a> / <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code</a> / <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard</a></p>
              
              <p><i>Tuberculosis Prediction</i>, ImageCLEF, 2019 (<font color="red">5th Place</font>) <br>
                <a href="https://arxiv.org/abs/2007.13224">Paper</a> / <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> / <a href="https://www.imageclef.org/2019/medical/tuberculosis">Leaderboard</a></p>
              
              <p><i>Bengali Handwritten Digit Recognition</i>, Bengali.AI, 2019 (<font color="red">6th Place</font>) <br>
                <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/unconventional-wisdom">Code</a> / <a href="https://www.kaggle.com/competitions/numta/leaderboard">Leaderboard</a></p>
  
              </td>
        </tr>
      </table>   
  
      <hr>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Datasets</heading>
            <p>These include datasets I've created.</p>
            <p></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='rsud20k.png'></div>
            <img src='rsud20k.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2401.07322">
          <papertitle>Bangladesh Road Scene Understanding Dataset for Autonomous Driving</papertitle></a><br>
          <strong>Hasib Zunair</strong>, Shakib Khan, A. Ben Hamza<br> 
          <em>IEEE International Conference on Image Processing</em>, 2024<br>
          <a href="https://www.kaggle.com/datasets/hasibzunair/rsud20k-bangladesh-road-scene-understanding">Dataset Link</a>
          </p>
            <p>
              A dataset with 20K high-resolution images and 130K bounding box annotations. 
              Benchmark object detectors and explore large vision language models (LVLMs) as image annotators.
            </p>
          </td>
        </tr>
      </table>
      

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='covid.png'></div>
            <img src='covid.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
    <p><a href="https://arxiv.org/abs/2106.09759">
          <papertitle>Synthetic Dataset of COVID-19 Chest X-rays</papertitle></a><br>
          <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>ICML Workshop on Computational Biology</em>, 2021<br>
          <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset Link</a>
          </p>
            <p>Collection of 21,295 synthetic COVID-19 chest X-ray images. 
              The primary use of this dataset is to be used as additional data for training machine learning models.
            </p>
          </td>
        </tr>
      </table>
    
    <hr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Other Projects</heading>
            <p>These include coursework, side projects and unpublished research work.</p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='resm3dvton.png'></div>
            <img src='resm3dvton.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://hasibzunair.github.io/resm3dvton/resources/paper.pdf">
          <papertitle>Monocular-to-3D Virtual Try-On using Deep Residual U-Net</papertitle></a><br>
          <strong> Hasib Zunair</strong> <br>
          <em><a href="https://users.encs.concordia.ca/~stpopa/page_comp6381.html">COMP 6381 Digital Geometric Modelling</a></em>, Fall 2021<br>
          <a href="https://hasibzunair.github.io/resm3dvton/">Project Page</a> / 
          <a href="https://github.com/hasibzunair/res-m3d-vton">Code</a> 
          <p>
            A pipeline for monocular to 3D virtual try-on to synthesize correct clothing parts, 
            preserve logo of clothing and reduce artifacts to finally output better textured 3D try-on meshes.
          </p>
          </td>
        </tr>
      </table>

        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='fastmri2019.png'></div>
            <img src='fastmri2019.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/hasibzunair/res-unet-fastmri">Low to high resolution knee MRI reconstruction</a></papertitle></a><br>
                <strong> Hasib Zunair</strong>, Aimon Rahman<br>
                <a href="https://fastmri.org/leaderboards/challenge/2019/"><em>fastMRI Image Reconstruction Challenge</em></a>, 2019
                <br>
            <p>We use deep encoder-decoder architectures to reconstruct a high resolution knee MRI 
              image given a low resolution MRI image.
            </p>
          </td>
        </tr>
        </tbody></table>

    <table width="100%" align="center" border="0" cellpadding="10"><tbody>
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
          <div class="two" id = 'aperture_image'><img src='thyroid.png'></div>
          <img src='thyroid.png'>
          </div>
          <script type="text/javascript">
          function aperture_start() {
          document.getElementById('aperture_image').style.opacity = "1";
          }
          function aperture_stop() {
          document.getElementById('aperture_image').style.opacity = "0";
          }
          aperture_stop()
          </script>
        </td>
        <td valign="top" width="75%">
              <papertitle> <a href="https://github.com/hasibzunair/thyroid-nodule-sc">Thyroid nodule segmentation from Ultrasound (US) images</a></papertitle></a><br>
              <strong> Hasib Zunair</strong>, Tajwar Abrar Aleef, Aimon Rahman and Labib Chowdhury<br>
              <a href="https://tn-scui2020.grand-challenge.org/"><em>MICCAI TN-SCUI Challenge</em></a>, 2020
              <br>
          <p> Benchmark several semantic segmentation methods for thyroid nodule segmentation task inlcuding supervised learning, transfer learning, 
            and generative adversarial learning.
          </p>
        </td>
      </tr>
      </tbody></table>

      <hr>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Tutorials & Invited Talks</heading>
            <p></p>
              <a href="https://www.youtube.com/playlist?list=PLs_LQqhGAXZy5OG6Fu5R140BnyXmX_lPQ"> <p><i>Machine Learning Research Paper Writing Tutorial</i></a>, 2024
              <a href="https://pub.towardsai.net/leveraging-vector-databases-with-embeddings-for-fast-image-search-and-retrieval-1782db5bbcd8"> <p><i>Leveraging Vector Databases with Embeddings for Fast Image Search and Retrieval</i></a>, 2024
              <a href="https://github.com/hasibzunair/generative-models-tutorial"> <p><i>Building and Applying Generative Models using PyTorch, Ericsson Canada</i></a>, 2024
              <a href="https://pub.towardsai.net/build-and-deploy-custom-docker-images-for-object-recognition-d0d127b2603b"> <p><i>Build and Deploy Custom Docker Images for Object Recognition, Towards AI</i></a>, 2023
              <a href="https://github.com/hasibzunair/cv-pytorch-tutorials"> <p><i>Deep Learning in Computer Vision with PyTorch</i></a>, 2023
              <a href="https://github.com/hasibzunair/neural-nets-for-babies"> <p><i>Intro to Deep Learning with NumPy, NSU</i></a>, 2022
              <a href="https://github.com/hasibzunair/ericsson-upskill-tutorials"> <p><i>Building ML models with TensorFlow, Ericsson Canada</i></a>, 2021
              <a href="https://docs.google.com/presentation/d/1qv7Lww9C9xgydvIYxzPBvugvEHsWnYYLyblXuP1HcPc/edit#slide=id.p"> <p><i>How to get started with building Computer Vision systems, NSU</i></a>, 2021
              <a href="https://keras.io/examples/vision/3D_image_classification/"> <p><i>3D image classification from CT scans, Keras, TensorFlow</i></a>, 2020
              <a href="https://github.com/hasibzunair/ieee19-py"> <p><i>Programming with Python, NSU</i></a>, 2019
              <a href="https://github.com/hasibzunair/whats-image-classifcation-really"> <p><i>Intro to Deep Learning for Image Classification using Python, NSU</i></a>, 2019
              <a href="https://github.com/hasibzunair/ieee18-cv"> <p><i>Basics of Image Processing and Computer Vision, NSU</i></a>, 2018         
              <p><i>Intro to Robotics (ROBO101), a semester-long series of workshops, NSU</i>, 2018
          </td>
        </tr>
      </table>   

      <hr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      </font>
        </p>
        <p align="right">
          <font size="2">
          Template stolen from <a href="https://jonbarron.info/">Jon Barron</a>! Thanks for dropping by.<br>
          Last updated December 2024.
          </font>
        </p>

    </td>
    </tr>
  </table>
  </body>
</html>