<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=‚Äúwidth=800‚Äù>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    position: relative;
    }
    .two
    {
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  
<!--
  width: 0;
  height: 0;
-->

  <title>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="my_icon.png">
  </head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</name>
        </p>
        <!--
	Comment..
        -->
        <p>Aloha! I'm a graduating Ph.D candidate at <a href="https://www.concordia.ca/">Concordia</a> advised by 
          <a href="https://users.encs.concordia.ca/~hamza/">Prof. A. Ben Hamza</a>. I am also an Applied ML Scientist at 
          <a href="https://www.decathlon.ca/en/">D√©cathlon</a> where I build machine learning solutions that transform sport 
          images and videos into actionable intelligence. Previously, I've also spent time 
          at <a href="https://www.ericsson.com/en">Ericsson</a> as a 
          <a href="https://www.concordia.ca/news/stories/2021/11/18/concordia-and-ericsson-canada-team-up-to-integrate-and-enhance-applied-ai-research-and-development.html">ML Specialist</a>.
          I obtained my MASc at Concordia where my <a href="https://spectrum.library.concordia.ca/id/eprint/988565/2/Zunair_MASc_S2021.pdf">thesis</a> focused on generative modeling (now Generative AI) 
          for biomedical image understanding. üëÄ
        </p>

        <!--
          Before that, I independently worked on computer vision research problems with 
          <a href="http://ece.northsouth.edu/people/dr-nabeel-mohammed/">Dr. Nabeel Mohammed</a>,
          <a href="https://scholar.google.com/citations?hl=en&user=IUwFD9gAAAAJ&view_op=list_works&sortby=pubdate">Dr. M. Sohel Rahman</a> and
          <a href="http://ece.northsouth.edu/people/mahdy-rahman-chowdhury/">Dr. Mahdy Rahman</a>.
        -->

        <p>
          During my bachelors at <a href="http://www.northsouth.edu/">North South University (NSU)</a> 
          in <a href="https://en.wikipedia.org/wiki/Bangladesh">Bangladesh</a>, 
          I founded and led the first <a href="https://www.facebook.com/ieeensu.ras/">IEEE Robotics and Automation Society (RAS)</a> 
          in Bangladesh when I dabbled in <a href="https://www.youtube.com/playlist?list=PLs_LQqhGAXZyomFpmBE-HrXkuHNe3q9uN">robotics</a>, leading to 
          <a href="https://www.facebook.com/ieeerasbd/">IEEE BD RAS</a>. ü§ñ
        </p>

        <p>
        I like to read self-help books, workout, cook fancy meals and spend time in nature. I also like funny 
        animal <a href="https://www.instagram.com/barked/?hl=en">videos</a>! üêï
        </p>

        <p align=center>
          <a href="mailto:hasibzunair@gmail.com">Email</a> &nbsp/&nbsp
          <!-- 
            add cv link in between href "" 

            Link: 
           
          <a href="">CV</a> &nbsp/&nbsp
           -->
          <a href="https://www.linkedin.com/in/hasib-zunair-3a4487152/"> LinkedIn </a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=A_0zJN0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/hasibzunair">GitHub</a> &nbsp/&nbsp
          <a href="https://www.youtube.com/@hasibzunair"> YouTube</a> &nbsp/&nbsp
          <a href="https://hasibzunair.medium.com/"> Medium</a> &nbsp/&nbsp
          <a href="https://twitter.com/hasibzunair"> Twitter</a>

          
        </p>
        </td>
        <td style="padding:0;width:50%;max-width:50%">
        <a href="hasib_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="hasib_circle.png"></a>
        </td>
      </tr>
      </table>

      <hr>

    <!-- 
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>News</heading>
          <p>
            <ul>
              <li>17/12/2020: One Paper is Accepted at X.</li>
              <li>21/07/2020: Got into Y.  </li>
            </ul>
          </p>
        </td>
      </tr>
    </tbody></table>
    -->

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Bio</heading>  
          <p>
            My main focus is in the intersection of <strong>computer vision</strong>, <strong>machine learning</strong> and <strong>image processing</strong> with applications 
            in <strong>scene understanding</strong>, <strong>visual perception</strong> and <strong>generation</strong>. 
            I'm developing data-driven learning-based algorithms that enable computers to accurately and 
            efficiently understand, model and recreate the visual world around us; all while reducing the need 
            for intensive manual labeling required to build intelligent systems. üß†
          </p>
          
          <p>
            With over <strong>5 years of research experience</strong> in machine learning and computer vision (ML/CV) 
            and more than <strong>20 peer-reviewed publications</strong>, 
            I have a strong lead-author publication record in top-tier conferences and journals like <strong>WACV</strong>, <strong>BMVC</strong> and  
            <strong>Transactions in Medical Imaging</strong>, as well as prestigious workshops at <strong>CVPR</strong>, <strong>ICML</strong> and <strong>MICCAI</strong>. 
            For my Ph.D research, I received the Doctoral Graduate Fellowship in addition to the 
            International Tuition Award of Excellence. In my MASc, I received the two-year MITACS Accelerate Fellowship. üî¨
          </p>

          <p>
            I have <strong>4 years of industry experience</strong> building production-grade end-to-end ML/CV solutions. This includes data 
            labeling, neural network training and evaluation, the science of making it work, and deployment on the cloud infrastructure and 
            edge devices. I've worked on a range of 
            problems, from <strong>image analysis</strong>, <strong>recognition</strong>, <strong>segmentation</strong> and <strong>object detection</strong>, 
            to <strong>visual search and retrieval engines</strong>, 
            to applications of computer vision in the <strong>fashion domain</strong>, to <strong>video-analysis</strong> in sports. üè≠
          </p>

          <p>
            I regularly <strong>contribute to open-source software</strong>, <strong>learn</strong>, <strong>teach</strong> and <strong>mentor</strong>. 
            I was the <strong>runner-up</strong> in several <strong>machine learning competitions</strong> and have <strong>contributed code</strong> to impactful projects like 
            <a href="https://github.com/meituan/YOLOv6/pull/685?fbclid=IwAR332dEHvp773_JFE41s8sszEJSJTBUtXssE9R1uvtpcXWkw9tn8PROsMIg"><strong>YOLOv6</strong></a>, 
              <a href="https://github.com/kornia/kornia/releases/tag/v0.6.4?fbclid=IwAR3ObxOHJi-YCwn6WA_4SLMfEAu7iSg_19VpUIOKjsGXS-Z6Go8Mb7tA0ME"><strong>Kornia</strong></a>, 
              and <a href="https://keras.io/examples/vision/3D_image_classification/"><strong>TensorFlow/Keras</strong></a>. 
              I‚Äôve mentored numerous undergraduate, master‚Äôs, and Ph.D students, and interns specializing in ML/CV. 
              I constantly learn about new technologies to keep up with field, and share my learnings through <a href="https://hasibzunair.medium.com/"><strong>blogs</strong></a> and <a href="https://www.youtube.com/@hasibzunair"><strong>videos</strong></a>. üò¨
          </p>
          
            <p>I support <a href="http://slow-science.org/">Slow Science</a>.</p>
          </p>
        </td>
      </tr>
      </table>

      <hr>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
            See also my Google Scholar profile for the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works&sortby=pubdate"> most recent publications</a> as well 
            as the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works">most-cited papers</a>.
          </p>
        </td>
      </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='rsud20k.png'></div>
            <img src='rsud20k.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2401.07322">
          <papertitle>RSUD20K: A Dataset for Road Scene Understanding In Autonomous Driving</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Shakib Khan, A. Ben Hamza<br> 
          <em>arXiv</em>, 2024<br>
          </p>
          <a href="https://arxiv.org/abs/2401.07322">Paper</a> / 
          <a href="https://github.com/hasibzunair/RSUD20K">Code</a> /
          <a href="https://huggingface.co/spaces/Shakib-IO/RSUD20K_DEMO">Demo</a>
            <p>
              RSUD20K is a new object detection dataset for road scene understanding, comprised of over 20K high-resolution images from 
              the driving perspective on Bangladesh roads, and includes 130K bounding box annotations for 13 objects. We benchmark recent object detectors 
              and explore Large Vision-Language models as image annotators.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='wacv2024-msl.png'></div>
            <img src='wacv2024-msl.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2310.18517">
          <papertitle>Learning to Recognize Occluded and Small Objects with Partial Inputs</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2024<br>
          </p>
          <a href="https://arxiv.org/abs/2310.18517">Paper</a> / 
          <a href="https://github.com/hasibzunair/msl-recognition">Code</a> /
          <a href="https://hasibzunair.github.io/msl-recognition/">Website</a>

            <p>
              We propose a learning algorithm to explicitly focus on context from neighbouring regions around objects 
              and learn a distribution of association across classes. Ideally to handle situations in-the-wild where only part of 
              some object class is visible, but where us humans might readily use context to infer the classes presence.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='arxiv2023-cosif.png'></div>
            <img src='arxiv2023-cosif.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/pii/S0010482524004013">
          <papertitle>CosSIF: Cosine similarity-based image filtering to overcome low inter-class variation in synthetic medical image datasets</papertitle></a><br>
          Authors : Mominul Islam, <strong>Hasib Zunair</strong>, Nabeel Mohammed<br> 
          <em>Computers in Biology and Medicine</em>, 2024<br>
          </p>
          <a href="https://arxiv.org/abs/2307.13842">Paper</a> / 
          <a href="https://github.com/mominul-ssv/cossif">Code</a>

            <p>
              This paper introduces Cosine Similarity-based Image Filtering (CosSIF), a robust dataset filtering algorithm. We 
              utilize CosSIF to create two filtering approaches: FBGT and FAGT. These methods rely on cosine similarity as the 
              main metric for similarity calculation and aim to reduce the volume of GAN-generated synthetic images from the 
              minority class that resemble similarity to images from the majority class. 
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bmvc2022-masksup.png'></div>
            <img src='bmvc2022-masksup.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2210.00923">
          <papertitle>Masked Supervised Learning for Semantic Segmentation</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>British Machine Vision Conference</em>, 2022<br>
          <font color="red">(Oral Presentation)</font></a>
          </p>
          <a href="https://arxiv.org/abs/2210.00923">Paper</a> / 
          <a href="https://github.com/hasibzunair/masksup-segmentation">Code</a> /
          <a href="https://bmvc2022.mpi-inf.mpg.de/0417_poster.pdf">Poster</a> / 
          <a href="https://bmvc2022.mpi-inf.mpg.de/0417_video.mp4">Video</a> 

            <p>
              Masked Supervised Learning (MaskSup) is an effective single-stage learning paradigm 
              that models both short- and long-range context, capturing the contextual relationships between 
              pixels via random masking. Results show good segmentation performance, particularly at handling 
              ambiguous regions and retaining better segmentation of 
              minority classes with no added inference cost.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='bmvc2022-fifa.png'></div>
            <img src='bmvc2022-fifa.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2210.00918">
          <papertitle>Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based Virtual Try-On</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Samuel Mercier, Yan Gobeil, A. Ben Hamza<br> 
          <em>British Machine Vision Conference</em>, 2022<br>
          </p>
          <a href="https://arxiv.org/abs/2210.00918">Paper</a> / 
          <a href="https://github.com/hasibzunair/fifa-tryon">Code</a> /
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_poster.pdf">Poster</a> / 
          <a href="https://bmvc2022.mpi-inf.mpg.de/0418_video.mp4">Video</a> 

            <p>
              FIFA is a a self-supervised conditional generative adversarial network based framework
              for virtual try-on. It consists of a Fabricator that aims to reconstruct the clothing image when provided with a masked clothing as input, 
              and learns the overall structure of the clothing by filling in fabrics. A 
              multi-scale structural constraint to enforce global context at multiple scales while 
              warping the target clothing to better fit the pose and shape of the person.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cimb2022_leuk.png'></div>
            <img src='cimb2022_leuk.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522010800">
          <papertitle>Quantifying imbalanced classification methods for leukemia detection</papertitle></a><br>
          Authors : Deponker SarkerDepto, Md. Mashfiq Rizvee, Aimon Rahman, <strong>Hasib Zunair</strong>, M. Sohel Rahman, M.R.C. Mahdy<br> 
          <em>Computers in Biology and Medicine</em>, 2022<br>
          </p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522010800">Paper</a> / 
          <a href="https://github.com/Deponker/imbalanced_classification_leukemia">Code</a> 

            <p>
              Automated identification of leukemia from microscopic image is crucial for 
              early detection as the disease progresses rapidly. However, building these automated systems are challenging 
              owing to fine-grained variability of lymphoid precursor cells and imbalanced data points. We benchmark several 
              methods (input, loss amd GAN-based etc) designed to tackle class imbalance and find that loss-based methods 
              outperform GAN-based and input-based methods for leukemia detection.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='vista_cvprw2022.png'></div>
            <img src='vista_cvprw2022.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2204.11024">
          <papertitle>VISTA: Vision Transformer enhanced by U-Net and Image Colorfulness Frame Filtration for Automatic Retail Checkout</papertitle></a><br>
          Authors : Md. Istiak Hossain Shihab‚Ä†, Nazia Tasnim‚Ä†, <strong>Hasib Zunair</strong>‚Ä†, Labiba Kanij Rupty, Nabeel Mohammed (‚Ä† equal contribution)<br>
          <em>AI City Challenge, CVPR Workshops</em>, 2022<br>
          </p>
          <a href="https://arxiv.org/abs/2204.11024">Paper</a> / 
          <a href="https://github.com/istiakshihab/automated-retail-checkout-aicity22">Code</a> /
          <a href="https://drive.google.com/file/d/14eXT3ek6xCs7UU4lQ-lyeNS80f0Oqpat/view?usp=sharing">Slides</a> /
          <a href="https://github.com/NVIDIAAICITYCHALLENGE/2022AICITY_Code_From_Top_Teams/">Leaderboard <font color="red">(3rd place)</font></a>
            <p>
              Given a frame from a video sequence, we first segment single product item and hand followed 
              by entropy masking to address the domain bias problem, and then a
              Vision Transformer (ViT) for multi-class classification. We also propose a custom metric that 
              discards frames not having any product items, utilizing several image 
              processing methods.Our method achieved 3rd place in the <a href="https://www.aicitychallenge.org/2022-data-and-evaluation/"> AI City Challenge, Track 4</a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cibm2022.png'></div>
            <img src='cibm2022.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522003730?via%3Dihub">
          <papertitle>Knowledge distillation approach towards melanoma detection</papertitle></a><br>
          Authors : Md Shakib Khan, Kazi Nabiul Istla, Abdur Rab Dhruba, <strong>Hasib Zunair</strong>, Nabeel Mohammed<br> 
          <em>Computers in Biology and Medicine</em>, 2022<br>
          </p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482522003730?via%3Dihub">Paper</a> / 
          <a href="https://github.com/Shakib-IO/KD-lesions">Code</a> 

            <p>
              Proposed a knowledge distillation approach for melanoma detection to reduce model complexitiy and enable 
              easier deployment in edge devices. The proposed method requires relatively less time to detect melanoma. The method 
              is 15 times smaller than EfficientNet-B0 and consistently achieves better performance in both melanoma and non-melanoma detection.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cu_thesis.jpg'></div>
            <img src='cu_thesis.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://spectrum.library.concordia.ca/id/eprint/988565/2/Zunair_MASc_S2021.pdf">
          <papertitle>Designing Efficient Deep Learning Models for Computer-Aided Medical Diagnosis</papertitle></a><br>
          Authors: <strong>Hasib Zunair</strong> <br>
          <em>Masters Thesis</em>, 2021<br>
          </p>
          <a href="https://spectrum.library.concordia.ca/id/eprint/988565/">Paper</a> / 
          <a href="https://github.com/hasibzunair/masters-thesis-projects">Code</a>
          <p>
            Annotating medical image data is time consuming, costly and error prone, and 
            the scarcity of labeled data limits the effectiveness of supervised learning. 
            This thesis introduces generative modeling methods and architectures to address the scarcity of labels as well as 
            class imbalance which results in a bias towards to over-represented class for tasks 
            such as classification, binary and multi-class semantic segmentation.
            </p>
        </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='sharpunet.png'></div>
            <img src='sharpunet.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004935">
          <papertitle>Sharp U-Net: Depthwise convolutional network for biomedical image segmentation</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>Computers in Biology and Medicine</em>, 2021<br>
          </p>
          <a href="https://arxiv.org/abs/2107.12461">Paper</a> / 
          <a href="https://github.com/hasibzunair/sharp-unets">Code</a> 

            <p>
              Sharp U-Net achieves improved performance on six medical image segmentation datasets
              in both binary and multi-class segmentation tasks while adding no extra learnable parameters. 
              The idea is instead of applying a plain skip connection, 
              a depthwise convolution of the encoder feature map with a sharpening kernel filter is done prior to merging the 
              encoder and decoder features.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='star_mmsports.png'></div>
            <img src='star_mmsports.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://dl.acm.org/doi/10.1145/3475722.3482791">
          <papertitle>STAR: Noisy Semi-Supervised Transfer Learning for Visual Classification</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Yan Gobeil, Samuel Mercier, A. Ben Hamza<br> 
          <em>ACM Workshop on Multimedia Content Analysis in Sports</em>, 2021<br>
          <font color="red">(Oral Presentation)</font></a>
          </p>
          <a href="https://arxiv.org/abs/2108.08362">Paper</a> / 
          <a href="https://github.com/Decathlon/decavision">Code</a> /
          <a href="https://decavision-doc.herokuapp.com/ssl_example.html">Decathlon Docs</a> /
          <a href="https://medium.com/decathlontechnology/improving-performance-of-image-classification-models-using-pretraining-and-a-combination-of-e271c96808d2">Blog Post</a> /
          <a href="https://drive.google.com/drive/folders/178j1L8wivD5h1q3wkfs0XbXPNpf2LdyS">Video</a>

            <p>
              An efficient semi-supervised learning method is proposed for binary and multi-class image classification.
              The method requires 6x less compute time and 5x less memory compared to prior arts. We also show that our method 
              boosts robustness of visual classification models, even without specifically optimizing for adversarial robustness.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>
      

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='clef2021.png'></div>
            <img src='clef2021.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="http://ceur-ws.org/Vol-2936/paper-121.pdf">
          <papertitle>ViPTT-Net: Video pretraining of spatio-temporal model for tuberculosis type classification from chest CT scans</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, and Nabeel Mohammed<br> 
          <em>Conference and Labs of the Evaluation Forum (CLEF)</em>, 2021<br>
          </p>
          <a href="https://arxiv.org/abs/2105.12810">Paper</a> / 
          <a href="https://github.com/hasibzunair/viptt-net">Code</a> /
          <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard <font color="red">(2nd place)</font></a>

            <p>We pretrain a model on videos for human activity recognition which leads to better 
              representations for the downstream tuberculosis type classification task, especially for under-represented class samples. 
              Our method achieved 2nd place in the <a href="https://www.imageclef.org/2021/medical/tuberculosis"> ImageCLEF 2021
                Tuberculosis Type Classification Challenge.</a></p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ISBI-MoNuSAC2020.png'></div>
            <img src='ISBI-MoNuSAC2020.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://ieeexplore.ieee.org/document/9446924">
          <papertitle>MoNuSAC2020: A Multi-organ Nuclei
            Segmentation and Classification Challenge</papertitle></a><br>
          Authors : Ruchika Verma, Neeraj Kumar, <strong> Hasib Zunair</strong>, A. Ben Hamza and others.<br> 
          <em>IEEE Transactions on Medical Imaging (TMI)</em>, 2021 <br>
          <em>ISBI MoNuSAC Workshop</em>, 2020 <font color="red">(Oral Presentation)</font> </p>
          <a href="https://ieeexplore.ieee.org/document/9446924">Paper </a> / 
          <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code </a> / 
          <a href="https://docs.google.com/presentation/d/11ym6YdXazpAhkqH348X8fyHmZEoLd81xozrPHAJko44/edit?usp=sharing">Slides</a> / <a href="https://youtu.be/QztsH4IYQRA">Video (Time - 1:58:46)</a> /
          <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard </a> <font color="red">(11th place)</font>
          
          <p>
              Automating the tasks of detecting, segmenting, and classifying cell nuclei can free up the pathologists‚Äô time
              for higher value tasks and reduce errors due to fatigue and subjectivity. This paper summarizes and publicly releases
              the challenge dataset, and compile key findings of the
              methods developed by various participants.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
        </table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='covid.png'></div>
            <img src='covid.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
	  <p><a href="https://link.springer.com/article/10.1007/s13278-021-00731-5">
          <papertitle>Synthesis of COVID-19 Chest X-rays using Unpaired Image-to-Image Translation</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>ICML Workshop on Computational Biology</em>, 2021 <font color="red">(Poster Presentation)</font><br>
          <em>Social Network Analysis and Mining</em>, 2021</p>
          <a href="https://arxiv.org/abs/2010.10266">Paper</a> / 
          <a href="https://arxiv.org/abs/2106.09759">ICML WCB Short Paper</a> /
          <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset</a>
           
            <p> Propose synthetic image data by leveraging class conditioning and adversarial training that achieve results 
              comparable to training with only real data when using a test set of real images. Also combine synthetic data 
              with different sizes of real datasets for additional performance gains.
             </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell2.png' width="160"></div>
            <img src='tissueandcell2.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">
          <papertitle>Automatic segmentation of blood cells from microscopic slides: A comparative analysis</papertitle></a><br>
          Authors : Deponker Sarker Depto, Shazidur Rahman, Md. Mekayel Hosen, Mst Shapna Akter, 
          Tamanna Rahman Reme, Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021</p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">Paper</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation-dataset">Dataset</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation">Code</a>
           
            <p>

            This work proposes a blood cell segmentation dataset consisting of multiple cell types. 
            Additionally, all cell types 
            do not have equal instances, which encourages researchers to develop algorithms for 
            learning from imbalanced classes in a few shot learning paradigm. We also provide both learning and non-learning based
            methods as baselines.

            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell.png' width="160"></div>
            <img src='tissueandcell.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub">
          <papertitle>A Comparative Analysis of Deep Learning Architectures on High Variation Malaria Parasite Classification Dataset</papertitle></a><br>
          Authors : Aimon Rahman, <strong>Hasib Zunair</strong>, Tamanna Rahman Reme, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021</p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub6">Paper</a>
           
            <p>Transformed a high variation malaria localization dataset into a malaria classification dataset. Several 
           classification algorithm benchmarks are provided for the task of classifying presence of malaria from microscopic images of isolated red blood cells.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='PRIME-MICCAI2020.jpg'></div>
            <img src='PRIME-MICCAI2020.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://link.springer.com/chapter/10.1007%2F978-3-030-59354-4_15">
          <papertitle>Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed, and Joseph Paul Cohen<br> 
          <em>PRIME MICCAI</em>, 2020<br>
          <a href="https://arxiv.org/abs/2007.13224">Paper</a> / 
          <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> /
          <a href="https://youtu.be/IP6poudyny4">Video</a>

            <p>Showed that analyzing 3D medical images in a per slice basis is a sub-optimal approach, that can be improved by 3D context. Ranked 5-th in <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019</a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='MelaNet-PMB.jpg'></div>
            <img src='MelaNet-PMB.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://iopscience.iop.org/article/10.1088/1361-6560/ab86d3">
          <papertitle>Melanoma Detection using Adversarial Training and Deep Transfer Learning</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>Physics in Medicine and Biology</em>, 2020</p>
          <a href="https://arxiv.org/abs/2004.06824">Paper</a> / <a href="https://github.com/hasibzunair/adversarial-lesions">Code</a> / <a href="https://aiderm.herokuapp.com/">Demo</a> <font color="red">(Try it out!)</font> 
           
            <p>Improved classification performance by synthesizing under-represented class samples from the over-represented ones. Synthetic samples are used as additional training data to reduce class imbalance.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='robust-dsr-AppSci.png'></div>
              <img src='robust-dsr-AppSci.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p><a href="https://www.mdpi.com/2076-3417/10/21/7522?fbclid=IwAR14F6l9F8UKvhReG273_ZLl5YnWKUuRAu4INNP1uNGfxhAWrdlipnN9Yd8">
            <papertitle>Robust Deep Speaker Recognition: Learning Latent Representation with Joint Angular Margin Loss</papertitle></a><br>
            Authors : Labib Chowdhury, <strong>Hasib Zunair</strong> and Nabeel Mohammed<br>
            <em>Applied Sciences</em>, 2020</p>
            <a href="https://www.mdpi.com/2076-3417/10/21/7522/htm">Paper</a> / <a href="https://github.com/jongli747/robust-dsr">Code</a></a>
  
              <p>SincNet models based on joint angular margin loss not only consistently outperformed current prior models, 
                but also generalizes well on unseen and diverse tasks such as Bengali speaker recognition.</p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='malariadetection2019.png'></div>
          <img src='malariadetection2019.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1907.10418">
        <papertitle>Improving Malaria Parasite Detection from Red Blood Cell using Deep Convolutional Neural Networks</papertitle></a><br>
        Authors : Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, Jesia Quader Yuki, Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy<br> 
        <em>arXiv</em>, 2019</p>
        <a href="https://arxiv.org/abs/1907.10418">Paper</a> / <a href="https://github.com/hasibzunair/malaria-detection">Code</a>            
          <p>Benchmarked several classification algorithms for the task of detecting malaria from microscopic images of red blood cells. Transfer learning approach worked best in our study.</p>
          </a></p>
        </td>
        </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='imageclef2019.jpg'></div>
            <img src='imageclef2019.jpg'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
        <td valign="top" width="75%">
            <p><a href="http://www.dei.unipd.it/~ferro/CLEF-WN-Drafts/CLEF2019/paper_77.pdf">
              <papertitle>Estimating Severity from CT Scans of Tuberculosis Patients using 3D Convolutional Nets</papertitle></a><br>
                Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed<br>
              <em>Conference and Labs of the Evaluation Forum (CLEF)</em>, 2019</p>
          <a href="https://www.researchgate.net/publication/334680379_Estimating_Severity_from_CT_Scans_of_Tuberculosis_Patients_using_3D_Convolutional_Nets_and_Slice_Selection">Paper</a> / <a href="https://github.com/hasibzunair/tuberculosis-severity">Code</a>
          <p></p>
          <p>A 3D CNN with a slice selection method employed in the task of chest CT image analysis
            for predicting tuberculosis (TB). Our method achieved 10-th place in the <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019
              Tuberculosis SVR - Severity scoring</a>.
          </p>
          </td>
          </tr>
          </table>

    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> 
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='unconventionalwisdom2018.png'></div>
          <img src='unconventionalwisdom2018.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8554435">
        <papertitle>Unconventional Wisdom: A New Transfer Learning Approach Applied to Bengali Numeral Classification</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Nabeel Mohammed, Sifat Momen<br> 
        <em>International Conference on Bangla Speech and Language Processing (ICBSLP)</em>, 2018<br>
          <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/kaggle_numtaDB">Code</a>
         
          <p>An accuracy of 97.09% was achieved on the NumtaDB Bengali handwritten digit dataset, which was obtained by freezing intermediate layers. </p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='web-attendance.png'></div>
          <img src='web-attendance.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535928">
        <papertitle>Design and Implementation of an Automated Web Based Multifunctional Attendance System</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Oishi Maniha, Jubayer Kabir<br> 
        <em>International Conference on Smart Sensors and Applications (ICSSA)</em>, 2018<br>
        <font color="red">(Best Student Paper)</font></p>
          <a href="https://www.researchgate.net/publication/327668463_Design_and_Implementation_of_an_Automated_Multi-Functional_Attendance_System_with_Real_Time_Web_Visualization">Paper</a> / <a href="https://drive.google.com/open?id=1-TZIqdn-yAMrQZzFy0vFnX2vNpStaBKK">Slides</a>
          <p></p>
          <p>Implementation of an automated multifunctional attendance system which uses rfid, fingerprint, and real time facial recognition.</p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>



    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='IOT-Vessels.png'></div>
          <img src='IOT-Vessels.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535976">
        <papertitle>Design and Implementation of an IOT based Monitoring System for Inland Vessels using Multiple Sensor Network</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Wordh Ul Hasan, Kimia Tuz Zaman, Irfanul Haque, Soumic Shekhar Aoyon<br>
        <em>International Conference on Smart Sensors and Applications (ICSSA)</em>, 2018<br>
          <a href="https://www.researchgate.net/publication/324173874_Design_and_Implementation_of_an_IoT_Based_Monitoring_System_for_Inland_Vessels_Using_Multiple_Sensors_Network">Paper</a> / <a href="https://drive.google.com/open?id=1pQc4Q5gT4CLA_1_DUx2Ln04lcYBeDR2q">Slides</a>
          <p></p>
          <p>A wireless sensor
network with a real time web application for monitoring
multiple ships to prevent catastrophic events due to
overloading.</p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='ams2017.png'></div>
          <img src='ams2017.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8424310/">
        <papertitle>Design and Implementation of Security Patrol Robot using Android Application</papertitle></a><br>
        Authors : Tahzib Mashrik, <strong> Hasib Zunair</strong>, Maofic Farhan Karin<br> 
        <em>Asia Modelling Symposium (AMS)</em>, 2017<br>
        <a href="https://www.researchgate.net/publication/323695337_Design_and_Implementation_of_Security_Patrol_Robot_using_Android_Application">Paper</a>
        <p>A low-cost autonomous mobile security robot based on a multisensor system for the purpose of sending alarms remotely. </p>
        </td>
      </tr>
    </table>

      <hr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Software Projects</heading>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='resm3dvton.png'></div>
            <img src='resm3dvton.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://hasibzunair.github.io/resm3dvton/resources/paper.pdf">
          <papertitle>Monocular-to-3D Virtual Try-On using Deep Residual U-Net</papertitle></a><br>
          <em>COMP 6381 Digital Geometric Modelling</em>, Fall 2021<br>
          </p>
          <a href="https://hasibzunair.github.io/resm3dvton/">Project Page</a> / 
          <a href="https://github.com/hasibzunair/res-m3d-vton">Code</a> 
          <p>
            Res-M3D-VTON is a pipeline for monocular to 3D virtual try-on (VTON) 
            for fashion clothing which uses residual learning to synthesize correct clothing parts, 
            preserve logo of clothing and reduce artifacts to finally output better textured 
            3D try-on meshes.
          </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="jump_stop()" onmouseover="jump_start()" >
            <td width="25%">
              <div class="one">
                <div class="two" id = 'jump_image'><img src='melanoma_detection_application.png'></div>
                <img src='melanoma_detection_application.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }
                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p><a href="https://github.com/hasibzunair/adversarial-lesions-app-demo"><papertitle>Dermatology Assistant</papertitle></a><br></p>
                <a href="https://github.com/hasibzunair/adversarial-lesions">AI Model Code</a> / <a href="https://github.com/hasibzunair/adversarial-lesions-rest-api-demo">REST API Code</a>
                <p>This is a demonstration of a full stack deep learning project from training a model 
                  to deploying it, using a REST API endpoint as well a separate end-user prototype web application. The 
                  model is built for predicting the presence of melanoma from dermoscopic skin lesions using 
                  neural networks.
                </p>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='fastmri2019.png'></div>
            <img src='fastmri2019.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/hasibzunair/res-unet-fastmri">Low to high resolution knee MRI reconstruction</a></papertitle></a><br>
                Collaborators: Aimon Rahman<br>
                <a href="https://fastmri.org/leaderboards/challenge/2019/"><em>fastMRI Image Reconstruction Challenge</em></a>, 2019
                <br>
            <p>We use deep encoder-decoder architectures to reconstruct a high resolution knee MRI 
              image given a low resolution MRI image.
            </p>
          </td>
        </tr>
        </tbody></table>

        

      <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='thyroid.png'></div>
            <img src='thyroid.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/hasibzunair/thyroid-nodule-sc">Thyroid nodule segmentation from Ultrasound (US) images</a></papertitle></a><br>
                Collaborators: Tajwar Abrar Aleef, Aimon Rahman and Labib Chowdhury<br>
                <a href="https://tn-scui2020.grand-challenge.org/"><em>MICCAI TN-SCUI Challenge</em></a>, 2020
                <br>
            <p>In this work, several state-of-the-art image segmentation techniques were explored for optimizing 
              Thyroid Nodule segmentation from Ultrasound images. This inlcuded supervised learning, transfer learning, 
              and generative adversarial learning.
            </p>
          </td>
        </tr>
        </tbody></table>

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Machine Learning Competitions</heading>
              <p></p>
              <p><i>Product Counting and Recognition for Retail Checkout</i>, AI City Challenge, CVPR Workshop, 2022 (<font color="red">3rd Place</font>) <br>
                <a href="https://arxiv.org/abs/2204.11024">Paper</a> / <a href="https://github.com/istiakshihab/automated-retail-checkout-aicity22">Code</a> / <a href="https://github.com/NVIDIAAICITYCHALLENGE/2022AICITY_Code_From_Top_Teams/#track-4-multi-class-product-counting--recognition-for-automated-retail-checkout">Leaderboard</a></p>

                <p><i>Tuberculosis Type Classification</i>, ImageCLEF, 2021 (<font color="red">2nd Place</font>) <br>
                  <a href="https://arxiv.org/abs/2105.12810">Paper</a> / <a href="https://github.com/hasibzunair/viptt-net">Code</a> / <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard</a></p>

                <p><i>Nuclei Segmentation and Classification</i>, MoNuSAC, 2020 (<font color="red">11th Place</font>) <br>
                  <a href="https://www.researchgate.net/profile/Ruchika-Verma-3/publication/352228330_L11_Patch_Efficient_Convolutional_Network_for_Multi-Organ_Nuclei_Segmentation_and_Classification/links/60c011c4a6fdcc512815fac6/L11-Patch-Efficient-Convolutional-Network-for-Multi-Organ-Nuclei-Segmentation-and-Classification.pdf">Paper</a> / <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code</a> / <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard</a></p>
                
                <p><i>Tuberculosis Prediction</i>, ImageCLEF, 2019 (<font color="red">5th Place</font>) <br>
                  <a href="https://arxiv.org/abs/2007.13224">Paper</a> / <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> / <a href="https://www.imageclef.org/2019/medical/tuberculosis">Leaderboard</a></p>
                
                <p><i>Bengali Handwritten Digit Recognition</i>, Bengali.AI, 2019 (<font color="red">6th Place</font>) <br>
                  <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/unconventional-wisdom">Code</a> / <a href="https://www.kaggle.com/competitions/numta/leaderboard">Leaderboard</a></p>

                </td>
          </tr>
        </table>   

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Datasets</heading>
              <p></p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='rsud20k.png'></div>
              <img src='rsud20k.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p><a href="https://arxiv.org/abs/2401.07322">
            <papertitle>RSUD20K: A Dataset for Road Scene Understanding In Autonomous Driving</papertitle></a><br>
            Authors : <strong>Hasib Zunair</strong>, Shakib Khan, A. Ben Hamza<br> 
            <em>arXiv</em>, 2024<br>
            </p>
            <a href="https://www.kaggle.com/datasets/hasibzunair/rsud20k-bangladesh-road-scene-understanding">Dataset Link</a>
  
              <p>
                RSUD20K is a new object detection dataset for road scene understanding, comprised of over 20K high-resolution images from 
                the driving perspective on Bangladesh roads, and includes 130K bounding box annotations for 13 objects..
              </p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='covid.png'></div>
              <img src='covid.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
      <p><a href="https://arxiv.org/abs/2106.09759">
            <papertitle>Synthetic COVID-19 Chest X-ray Dataset for Computer-Aided Diagnosis</papertitle></a><br>
            Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
            <em>ICML Workshop on Computational Biology</em>, 2021 <font color="red">(Poster Presentation)</font><br>
            </p>
            <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset Link</a>
              <p>The dataset consists of 21,295 synthetic COVID-19 chest X-ray images generated using <a href="https://github.com/hasibzunair/synthetic-covid-cxr-gen">algorithm</a>. 
                Dataset is publicly available <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset/releases/tag/v0.1">here</a>. The primary use of this dataset
                is to be used as additional data for training machine learning models.
               </p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>

        <hr>

<!-- 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
              <p>
              
              <p>Intro to Deep Learning with PyTorch, 2022</p>
              <p>Building ML models with TensorFlow, Ericsson Canada, 2021</p>
              <p>3D image classification from CT scans, Keras, TensorFlow, 2020</p>
              <p>Intro to Deep Learning for Image Classification using Python, NSU, 2019</p>
              <p> <a href="https://github.com/hasibzunair/whats-image-classifcation-really"></a>Basics of Image Processing and Computer Vision, NSU, 2018</p>
              <p>Intro to Python Programming, NSU, 2018</p>
              </p>
            </td>
          </tr>
          </table>
-->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Teaching</heading>
            <p></p>
          </td>
        </tr>
      </table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="comp6771.jpg"></td>
            <td width="75%" valign="center">
              Lab Demonstrator, <a href="https://github.com/myconcordia/COMP478"> COMP 6771: Image Processing</a>, Winter 2022
              <br>
              Lab Demonstrator, <a href="https://users.encs.concordia.ca/~gregb/home/comp333-f2021.html"> COMP 333: Intro to Data Analytics</a>, Fall 2021
              <br>
              Lab Demonstrator, <a href="https://github.com/myconcordia/COMP478"> COMP 6771: Image Processing</a>, Winter 2021
            </td>
          </tr>          
        </tbody></table>

        <hr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Invited Talks & Tutorials</heading>
              <p></p>
                <a href="https://pub.towardsai.net/build-and-deploy-custom-docker-images-for-object-recognition-d0d127b2603b"> <p><i>Build and Deploy Custom Docker Images for Object Recognition, Towards AI</i></a>, 2023
                <a href="https://github.com/hasibzunair/cv-pytorch-tutorials"> <p><i>Deep Learning in Computer Vision with PyTorch</i></a>, 2023
                <a href="https://github.com/hasibzunair/neural-nets-for-babies"> <p><i>Intro to Deep Learning with NumPy, NSU</i></a>, 2022
                <a href="https://github.com/hasibzunair/ericsson-upskill-tutorials"> <p><i>Building ML models with TensorFlow, Ericsson Canada</i></a>, 2021
                <a href="https://docs.google.com/presentation/d/1qv7Lww9C9xgydvIYxzPBvugvEHsWnYYLyblXuP1HcPc/edit#slide=id.p"> <p><i>How to get started with building Computer Vision systems, NSU</i></a>, 2021
                <a href="https://keras.io/examples/vision/3D_image_classification/"> <p><i>3D image classification from CT scans, Keras, TensorFlow</i></a>, 2020
                <a href="https://github.com/hasibzunair/ieee19-py"> <p><i>Programming with Python, NSU</i></a>, 2019
                <a href="https://github.com/hasibzunair/whats-image-classifcation-really"> <p><i>Intro to Deep Learning for Image Classification using Python, NSU</i></a>, 2019
                <a href="https://github.com/hasibzunair/ieee18-cv"> <p><i>Basics of Image Processing and Computer Vision, NSU</i></a>, 2018         
                <p><i>Intro to Robotics (ROBO101), a semester-long series of workshops, NSU</i>, 2018
            </td>
          </tr>
        </table>   

      <hr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      </font>
        </p>
        <p align="right">
          <font size="2">
          Template stolen from <a href="https://jonbarron.info/">Jon Barron</a>! Thanks for dropping by.<br>
          Last updated May 2024.
          </font>
        </p>

    </td>
    </tr>
  </table>
  </body>
</html>