<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=‚Äúwidth=800‚Äù>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    position: relative;
    }
    .two
    {
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  
<!--
  width: 0;
  height: 0;
-->

  <title>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="my_icon.png">
  </head>

  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Hasib Zunair / ‡¶π‡¶æ‡¶∏‡¶ø‡¶¨ ‡¶ú‡ßÅ‡¶®‡¶æ‡¶Ø‡¶º‡ßá‡¶∞</name>
        </p>
        <!--
	Comment..
        -->
        <p>Hi! I am currently a Ph.D student with Graduate Doctoral Fellowship, working on computer 
          vision and machine learning advised by 
          <a href="https://users.encs.concordia.ca/~hamza/">Prof. A. Ben Hamza</a> at 
          <a href="https://www.concordia.ca/">Concordia University</a>, Montreal, Canada. I did
          my Masters at Concoridia where I focussed on the limitations of medical applications of computer vision.
          During my masters, I also recieved the two-year 
          <a href="https://www.mitacs.ca/en/programs/accelerate/fellowship">MITACS Accelerate Fellowship</a> to work jointly with Concordia and 
          <a href="https://www.decathlon.ca/en/">D√©cathlon</a> as a research intern on semi-supervised learning
          for object recognition.
          I've also spent time at <a href="https://www.smart-retina.com/">Think Bricks LLC</a> exploring 
          applications of computer vision in medical image analysis and at 
          <a href="http://www.thetechacademy.net/">The Tech Academy</a> building robots! ü§ñ
        </p>
        <p>
          During my bachelors at <a href="http://www.northsouth.edu/">North South University</a> 
          in <a href="https://en.wikipedia.org/wiki/Bangladesh">Bangladesh</a>, I was first exposed to research 
          when I was advised by <a href="http://ece.northsouth.edu/people/dr-nabeel-mohammed/">Prof. Nabeel Mohammed</a>. 
          I served as the 
          founding chair of <a href="https://ieeensusb.org/ieee-nsu-ras-sbc/">IEEE Robotics and Automation Society (RAS) 
            Student Branch Chapter</a> which 
          is the first RAS student chapter in Bangladesh</a>.
        </p>

        <p>
        I like to cook fancy meals <i>(beauty is in the eye of the beholder)</i> and play 
        e-sports, Dota 2 and CSGO, during my free time. I also like funny 
        dog <a href="https://www.instagram.com/barked/?hl=en">videos</a>! üêï
        </p>

        <p align=center>
          <a href="mailto:hasibzunair@gmail.com">Email</a> &nbsp/&nbsp
          <!-- 
            add cv link in between href "" 

            Link: 
           
          <a href="">CV</a> &nbsp/&nbsp
           -->
          <a href="https://www.linkedin.com/in/hasib-zunair-3a4487152/"> LinkedIn </a> &nbsp/&nbsp
          <a href="https://github.com/hasibzunair">GitHub</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=A_0zJN0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://twitter.com/hasibzunair"> Twitter</a>
        </p>
        </td>
        <td style="padding:0;width:50%;max-width:50%">
        <a href="hasib_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="hasib_circle.png"></a>
        </td>
      </tr>
      </table>

      <hr>

      <!-- 
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Research</heading>
          <p>
            My interest lies in medical applications of deep learning:
            <ul>
              <li> Medical Diagnosis, Prognosis, Domain Adaptation, Reconstruction.    </li>
              <li>Medical Imaging: Microscopy, WSI, Histopathology, Radiology, Ultrasounds. </li>
              <li>3D Medical Data. </li>
            </ul>

            additionally fundamental deep learning:
            <ul>
              <li> Adversarial Learning, Attacks and Defense. </li>
              
            </ul>

          </p>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>News</heading>
        <p>
          <ul>
            <li>17/12/2020: One Paper is Accepted at Tissue and Cell.</li>
            <li>21/09/2020: One Paper is Accepted at IJMPC.</li>
            <li>21/07/2020: One Paper is Accepted at PRIME MICCAI 2020.  </li>
            <li>27/11/2019: One Paper is Accepted at ICME 2019.</li>
            <li>30/09/2019: One Paper is Accepted at IEEE MoRSE 2019. </li>
          </ul>

        </p>
      </td>
    </tr>
  </tbody></table>
  -->


    <!-- 
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>News</heading>
          <p>
            <ul>
              <li>17/12/2020: One Paper is Accepted at Tissue and Cell.</li>
              <li>21/07/2020: One Paper is Accepted at PRIME MICCAI 2020.  </li>
            </ul>
          </p>
        </td>
      </tr>
    </tbody></table>
    -->


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>

           My research interests lies at the intersection of computer vision and machine learning, 
           with the goal of building human-level computer vision systems that can understand, model, and recreate 
           the visual world around us. I am working on algorithms for 
           <strong>visual perception, synthesis</strong> 
           (<em>object recognition, segmentation, generation, ...</em>) and 
           <strong>representation learning</strong> (<em>pre-training networks with strong, weak, 
             or no supervision, ...</em>) to 
           reduce the need for intensive manual labeling efforts. üß† üëÄ


          <p>I have a passion for AI, automation, open-source software and teaching. I have contributed code to Keras
            that demonstrates a deep learning workflow on 
            <a href="https://keras.io/examples/vision/3D_image_classification/">3D Image Classification from CT Scans</a>,
            which also got featured in a
            <a href="https://youtu.be/rcnKGMNyVu4">video by Henry AI Labs</a>. I've also built some
            projects including 
            <a href="https://github.com/hasibzunair/pynotify">Pynotify: A Python package to send emails</a> and 
            <a href="https://github.com/hasibzunair/boss-detector">Boss Detector: Changes monitor screen when your boss is near</a> üò¨ .
          </p>
          
          <p>I support <a href="http://slow-science.org/">Slow Science</a>.</p>
          </p>
        </td>
      </tr>
      </table>

      <hr>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
          <p>
            See also my Google Scholar profile for the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works&sortby=pubdate"> most recent publications</a> as well 
            as the <a href="https://scholar.google.com/citations?hl=en&user=A_0zJN0AAAAJ&view_op=list_works">most-cited papers</a>.
          </p>
        </td>
      </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='cu_thesis.jpg'></div>
            <img src='cu_thesis.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://spectrum.library.concordia.ca/id/eprint/988565/2/Zunair_MASc_S2021.pdf">
          <papertitle>Designing Efficient Deep Learning Models for Computer-Aided Medical Diagnosis</papertitle></a><br>
          Authors: <strong>Hasib Zunair</strong> <br>
          <em>Masters Thesis</em>, 2021<br>
          </p>
          <a href="https://spectrum.library.concordia.ca/id/eprint/988565/">Spectrum</a>
          <p>
            Annotating medical image data is time consuming, costly and error prone, and 
            the scarcity of labeled data limits the effectiveness of supervised learning. 
            This thesis introduces methods to address the scarcity of labels as well as 
            class imbalance which results in a bias towards to over-represented class for tasks 
            such as classification, binary and multi-class semantic segmentation.
            </p>
        </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='sharpunet.png'></div>
            <img src='sharpunet.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004935">
          <papertitle>Sharp U-Net: Depthwise convolutional network for biomedical image segmentation</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, A. Ben Hamza<br> 
          <em>Computers in Biology and Medicine</em>, 2021<br>
          </p>
          <a href="https://arxiv.org/abs/2107.12461">Paper</a> / 
          <a href="https://github.com/hasibzunair/sharp-unets">Code</a> 

            <p>
              Sharp U-Net achieves improved performance on six medical image segmentation datasets
              in both binary and multi-class segmentation tasks while adding no extra learnable parameters. 
              The idea is instead of applying a plain skip connection, 
              a depthwise convolution of the encoder feature map with a sharpening kernel filter is done prior to merging the 
              encoder and decoder features.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='star_mmsports.png'></div>
            <img src='star_mmsports.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://dl.acm.org/doi/10.1145/3475722.3482791">
          <papertitle>STAR: Noisy Semi-Supervised Transfer Learning for Visual Classification</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Yan Gobeil, Samuel Mercier, A. Ben Hamza<br> 
          <em>ACM Workshop on Multimedia Content Analysis in Sports</em>, 2021<br>
          <font color="red">(Oral Presentation)</font></a>
          </p>
          <a href="https://arxiv.org/abs/2108.08362">Paper</a> / 
          <a href="https://github.com/Decathlon/decavision">Code</a> /
          <a href="https://decavision-doc.herokuapp.com/ssl_example.html">Decathlon Docs</a> /
          <a href="https://medium.com/decathlontechnology/improving-performance-of-image-classification-models-using-pretraining-and-a-combination-of-e271c96808d2">Blog Post</a> /
          <a href="https://drive.google.com/drive/folders/178j1L8wivD5h1q3wkfs0XbXPNpf2LdyS">Video</a>

            <p>
              An efficient semi-supervised learning method is proposed for binary and multi-class image classification.
              The method requires 6x less compute time and 5x less memory compared to prior arts. We also show that our method 
              boosts robustness of visual classification models, even without specifically optimizing for adversarial robustness.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>
      

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='clef2021.png'></div>
            <img src='clef2021.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="http://ceur-ws.org/Vol-2936/paper-121.pdf">
          <papertitle>ViPTT-Net: Video pretraining of spatio-temporal model for tuberculosis type classification from chest CT scans</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, and Nabeel Mohammed<br> 
          <em>Conference and Labs of the Evaluation Forum (CLEF)</em>, 2021<br>
          </p>
          <a href="https://arxiv.org/abs/2105.12810">Paper</a> / 
          <a href="https://github.com/hasibzunair/viptt-net">Code</a> /
          <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard <font color="red">(2nd place)</font></a>

            <p>We pretrain a model on videos for human activity recognition which leads to better 
              representations for the downstream tuberculosis type classification task, especially for under-represented class samples. 
              Our method achieved 2nd place in the <a href="https://www.imageclef.org/2021/medical/tuberculosis"> ImageCLEF 2021
                Tuberculosis Type Classification Challenge.</a></p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='ISBI-MoNuSAC2020.png'></div>
            <img src='ISBI-MoNuSAC2020.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://ieeexplore.ieee.org/document/9446924">
          <papertitle>MoNuSAC2020: A Multi-organ Nuclei
            Segmentation and Classification Challenge</papertitle></a><br>
          Authors : Ruchika Verma, Neeraj Kumar, <strong> Hasib Zunair</strong>, A. Ben Hamza and others.<br> 
          <em>IEEE Transactions on Medical Imaging (TMI)</em>, 2021 <br>
          <em>ISBI MoNuSAC Workshop</em>, 2020 <font color="red">(Oral Presentation)</font> </p>
          <a href="https://ieeexplore.ieee.org/document/9446924">Paper </a> / 
          <a href="https://github.com/hasibzunair/MoNuSAC-ISBI-2020">Code </a> / 
          <a href="https://docs.google.com/presentation/d/11ym6YdXazpAhkqH348X8fyHmZEoLd81xozrPHAJko44/edit?usp=sharing">Slides</a> / <a href="https://youtu.be/QztsH4IYQRA">Video (Time - 1:58:46)</a> /
          <a href="https://monusac-2020.grand-challenge.org/Results/">Leaderboard </a> <font color="red">(11th place)</font>
          
          <p>
              Automating the tasks of detecting, segmenting, and classifying cell nuclei can free up the pathologists‚Äô time
              for higher value tasks and reduce errors due to fatigue and subjectivity. This paper summarizes and publicly releases
              the challenge dataset, and compile key findings of the
              methods developed by various participants.
            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
        </table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='covid.png'></div>
            <img src='covid.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
	  <p><a href="https://link.springer.com/article/10.1007/s13278-021-00731-5">
          <papertitle>Synthesis of COVID-19 Chest X-rays using Unpaired Image-to-Image Translation</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>ICML Workshop on Computational Biology</em>, 2021 <font color="red">(Poster Presentation)</font><br>
          <em>Social Network Analysis and Mining</em>, 2021</p>
          <a href="https://arxiv.org/abs/2010.10266">Paper</a> / 
          <a href="https://arxiv.org/abs/2106.09759">ICML WCB Short Paper</a> /
          <a href="https://github.com/hasibzunair/synthetic-covid-cxr-dataset">Dataset</a>
           
            <p> Propose synthetic image data by leveraging class conditioning and adversarial training that achieve results 
              comparable to training with only real data when using a test set of real images. Also combine synthetic data 
              with different sizes of real datasets for additional performance gains.
             </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell2.png' width="160"></div>
            <img src='tissueandcell2.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">
          <papertitle>Automatic segmentation of blood cells from microscopic slides: A comparative analysis</papertitle></a><br>
          Authors : Deponker Sarker Depto, Shazidur Rahman, Md. Mekayel Hosen, Mst Shapna Akter, 
          Tamanna Rahman Reme, Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021</p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">Paper</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation-dataset">Dataset</a> /
          <a href="https://github.com/Deponker/Blood-cell-segmentation">Code</a>
           
            <p>

            This work proposes a blood cell segmentation dataset consisting of multiple cell types. 
            Additionally, all cell types 
            do not have equal instances, which encourages researchers to develop algorithms for 
            learning from imbalanced classes in a few shot learning paradigm. We also provide both learning and non-learning based
            methods as baselines.

            </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='tissueandcell.png' width="160"></div>
            <img src='tissueandcell.png' width="160">
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub">
          <papertitle>A Comparative Analysis of Deep Learning Architectures on High Variation Malaria Parasite Classification Dataset</papertitle></a><br>
          Authors : Aimon Rahman, <strong>Hasib Zunair</strong>, Tamanna Rahman Reme, M Sohel Rahman, M.R.C.Mahdy<br> 
          <em>Tissue and Cell</em>, 2021</p>
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816620306315?via%3Dihub6">Paper</a>
           
            <p>Transformed a high variation malaria localization dataset into a malaria classification dataset. Several 
           classification algorithm benchmarks are provided for the task of classifying presence of malaria from microscopic images of isolated red blood cells.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>


       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='PRIME-MICCAI2020.jpg'></div>
            <img src='PRIME-MICCAI2020.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://link.springer.com/chapter/10.1007%2F978-3-030-59354-4_15">
          <papertitle>Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed, and Joseph Paul Cohen<br> 
          <em>PRIME MICCAI</em>, 2020<br>
          <font color="red">(Oral Presentation)</font></p>
          <a href="https://arxiv.org/abs/2007.13224">Paper</a> / 
          <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> /
          <a href="https://youtu.be/IP6poudyny4">Video</a>

            <p>Showed that analyzing 3D medical images in a per slice basis is a sub-optimal approach, that can be improved by 3D context. Ranked 5-th in <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019</a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='MelaNet-PMB.jpg'></div>
            <img src='MelaNet-PMB.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://iopscience.iop.org/article/10.1088/1361-6560/ab86d3">
          <papertitle>Melanoma Detection using Adversarial Training and Deep Transfer Learning</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong> and A. Ben Hamza<br> 
          <em>Physics in Medicine and Biology</em>, 2020</p>
          <a href="https://arxiv.org/abs/2004.06824">Paper</a> / <a href="https://github.com/hasibzunair/adversarial-lesions">Code</a> / <a href="https://aiderm.herokuapp.com/">Demo</a> <font color="red">(Try it out!)</font> 
           
            <p>Improved classification performance by synthesizing under-represented class samples from the over-represented ones. Synthetic samples are used as additional training data to reduce class imbalance.</p>
            <p></p>
            </a></p>
          </td>
        </tr>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='robust-dsr-AppSci.png'></div>
              <img src='robust-dsr-AppSci.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p><a href="https://www.mdpi.com/2076-3417/10/21/7522?fbclid=IwAR14F6l9F8UKvhReG273_ZLl5YnWKUuRAu4INNP1uNGfxhAWrdlipnN9Yd8">
            <papertitle>Robust Deep Speaker Recognition: Learning Latent Representation with Joint Angular Margin Loss</papertitle></a><br>
            Authors : Labib Chowdhury, <strong>Hasib Zunair</strong> and Nabeel Mohammed<br>
            <em>Applied Sciences</em>, 2020</p>
            <a href="https://www.mdpi.com/2076-3417/10/21/7522/htm">Paper</a> / <a href="https://github.com/jongli747/robust-dsr">Code</a></a>
  
              <p>SincNet models based on joint angular margin loss not only consistently outperformed current prior models, 
                but also generalizes well on unseen and diverse tasks such as Bengali speaker recognition.</p>
              <p></p>
              </a></p>
            </td>
          </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='malariadetection2019.png'></div>
          <img src='malariadetection2019.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1907.10418">
        <papertitle>Improving Malaria Parasite Detection from Red Blood Cell using Deep Convolutional Neural Networks</papertitle></a><br>
        Authors : Aimon Rahman, <strong>Hasib Zunair</strong>, M Sohel Rahman, Jesia Quader Yuki, Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy<br> 
        <em>arXiv</em>, 2019</p>
        <a href="https://arxiv.org/abs/1907.10418">Paper</a> / <a href="https://github.com/hasibzunair/malaria-detection">Code</a>            
          <p>Benchmarked several classification algorithms for the task of detecting malaria from microscopic images of red blood cells. Transfer learning approach worked best in our study.</p>
          </a></p>
        </td>
        </tr>
        </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='imageclef2019.jpg'></div>
            <img src='imageclef2019.jpg'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
        <td valign="top" width="75%">
            <p><a href="http://www.dei.unipd.it/~ferro/CLEF-WN-Drafts/CLEF2019/paper_77.pdf">
              <papertitle>Estimating Severity from CT Scans of Tuberculosis Patients using 3D Convolutional Nets</papertitle></a><br>
                Authors : <strong>Hasib Zunair</strong>, Aimon Rahman, Nabeel Mohammed<br>
              <em>Conference and Labs of the Evaluation Forum (CLEF)</em>, 2019</p>
          <a href="https://www.researchgate.net/publication/334680379_Estimating_Severity_from_CT_Scans_of_Tuberculosis_Patients_using_3D_Convolutional_Nets_and_Slice_Selection">Paper</a> / <a href="https://github.com/hasibzunair/tuberculosis-severity">Code</a>
          <p></p>
          <p>A 3D CNN with a slice selection method employed in the task of chest CT image analysis
            for predicting tuberculosis (TB). Our method achieved 10-th place in the <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019
              Tuberculosis SVR - Severity scoring</a>.
          </p>
          </td>
          </tr>
          </table>

    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> 
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='unconventionalwisdom2018.png'></div>
          <img src='unconventionalwisdom2018.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8554435">
        <papertitle>Unconventional Wisdom: A New Transfer Learning Approach Applied to Bengali Numeral Classification</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Nabeel Mohammad, Sifat Momen<br> 
        <em>International Conference on Bangla Speech and Language Processing (ICBSLP)</em>, 2018<br>
        <font color="red">(Oral Presentation)</font></p></p>
          <a href="https://www.researchgate.net/publication/326989744_Unconventional_Wisdom_A_New_Transfer_Learning_Approach_Applied_to_Bengali_Numeral_Classification">Paper</a> / <a href="https://github.com/hasibzunair/kaggle_numtaDB">Code</a>
         
          <p>An accuracy of 97.09% was achieved on the NumtaDB Bengali handwritten digit dataset, which was obtained by freezing intermediate layers. </p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='web-attendance.png'></div>
          <img src='web-attendance.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535928">
        <papertitle>Design and Implementation of an Automated Web Based Multifunctional Attendance System</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Oishi Maniha, Jubayer Kabir<br> 
        <em>International Conference on Smart Sensors and Applications (ICSSA)</em>, 2018<br>
        <font color="red">(Oral Presentation, Best Paper)</font></p>
          <a href="https://www.researchgate.net/publication/327668463_Design_and_Implementation_of_an_Automated_Multi-Functional_Attendance_System_with_Real_Time_Web_Visualization">Paper</a> / <a href="https://drive.google.com/open?id=1-TZIqdn-yAMrQZzFy0vFnX2vNpStaBKK">Slides</a>
          <p></p>
          <p>Implementation of an automated multifunctional attendance system which uses rfid, fingerprint, and real time facial recognition.</p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>



    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='IOT-Vessels.png'></div>
          <img src='IOT-Vessels.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8535976">
        <papertitle>Design and Implementation of an IOT based Monitoring System for Inland Vessels using Multiple Sensor Network</papertitle></a><br>
        Authors : <strong>Hasib Zunair</strong>, Wordh Ul Hasan, Kimia Tuz Zaman, Irfanul Haque, Soumic Shekhar Aoyon<br>
        <em>International Conference on Smart Sensors and Applications (ICSSA)</em>, 2018<br>
        <font color="red">(Oral Presentation)</font></p>
          <a href="https://www.researchgate.net/publication/324173874_Design_and_Implementation_of_an_IoT_Based_Monitoring_System_for_Inland_Vessels_Using_Multiple_Sensors_Network">Paper</a> / <a href="https://drive.google.com/open?id=1pQc4Q5gT4CLA_1_DUx2Ln04lcYBeDR2q">Slides</a>
          <p></p>
          <p>A wireless sensor
network with a real time web application for monitoring
multiple ships to prevent catastrophic events due to
overloading.</p>
          <p></p>
          </a></p>
        </td>
      </tr>
    </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
          <div class="two" id = 'jump_image'><img src='ams2017.png'></div>
          <img src='ams2017.png'>
        </div>
        <script type="text/javascript">
          function jump_start() {
            document.getElementById('jump_image').style.opacity = "1";
          }
          function jump_stop() {
            document.getElementById('jump_image').style.opacity = "0";
          }
          jump_stop()
        </script>
      </td>


      <td valign="top" width="75%">
        <p><a href="https://ieeexplore.ieee.org/abstract/document/8424310/">
        <papertitle>Design and Implementation of Security Patrol Robot using Android Application</papertitle></a><br>
        Authors : Tahzib Mashrik, <strong> Hasib Zunair</strong>, Maofic Farhan Karin<br> 
        <em>Asia Modelling Symposium (AMS)</em>, 2017<br>
        <font color="red">(Oral Presentation)</font></p>
        <a href="https://www.researchgate.net/publication/323695337_Design_and_Implementation_of_Security_Patrol_Robot_using_Android_Application">Paper</a>
        <p>A low-cost autonomous mobile security robot based on a multisensor system for the purpose of sending alarms remotely. </p>
        </td>
      </tr>
    </table>

      <hr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Projects</heading>
          </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='resm3dvton.png'></div>
            <img src='resm3dvton.png'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://hasibzunair.github.io/resm3dvton/resources/paper.pdf">
          <papertitle>Monocular-to-3D Virtual Try-On using Deep Residual U-Net</papertitle></a><br>
          Authors : <strong>Hasib Zunair</strong><br> 
          <em>COMP 6381 Digital Geometric Modelling</em>, Fall 2021<br>
          </p>
          <a href="https://hasibzunair.github.io/resm3dvton/">Project Page</a> / 
          <a href="https://github.com/hasibzunair/res-m3d-vton">Code</a> 
          <p>
            Res-M3D-VTON is a pipeline for monocular to 3D virtual try-on (VTON) 
            for fashion clothing which uses residual learning to synthesize correct clothing parts, 
            preserve logo of clothing and reduce artifacts to finally output better textured 
            3D try-on meshes.
          </p>
            <p></p>
            </a></p>
          </td>
        </tr>
      </table>



        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="jump_stop()" onmouseover="jump_start()" >
            <td width="25%">
              <div class="one">
                <div class="two" id = 'jump_image'><img src='melanoma_detection_application.png'></div>
                <img src='melanoma_detection_application.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }
                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p><a href="https://aiderm.herokuapp.com/"><papertitle>Dermatology Assistant</papertitle></a><font color="red"> (Try it out!)</font>
                <br>
                Authors : <strong>Hasib Zunair</strong><br> </p>
                <a href="https://github.com/hasibzunair/adversarial-lesions">AI Model Code</a> / <a href="https://github.com/hasibzunair/adversarial-lesions-app-demo">Web App Code</a> / <a href="https://github.com/hasibzunair/adversarial-lesions-rest-api-demo">REST API Code</a>
                <p>This is a demonstration of a full stack deep learning project from training a model 
                  to deploying it, using a REST API endpoint as well a separate end-user prototype web application. The 
                  model is built for predicting the presence of melanoma from dermoscopic skin lesions using 
                  neural networks.
                </p>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='fastmri2019.png'></div>
            <img src='fastmri2019.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/hasibzunair/res-unet-fastmri">Low to high resolution knee MRI reconstruction</a></papertitle></a><br>
                Authors: <strong>Hasib Zunair</strong> and Aimon Rahman<br>
                <a href="https://fastmri.org/leaderboards/challenge/2019/"><em>fastMRI Image Reconstruction Challenge</em></a>, 2019
                <br>
            <p>We use deep encoder-decoder architectures to reconstruct a high resolution knee MRI 
              image given a low resolution MRI image.
            </p>
          </td>
        </tr>
        </tbody></table>

        

      <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
            <div class="two" id = 'aperture_image'><img src='thyroid.png'></div>
            <img src='thyroid.png'>
            </div>
            <script type="text/javascript">
            function aperture_start() {
            document.getElementById('aperture_image').style.opacity = "1";
            }
            function aperture_stop() {
            document.getElementById('aperture_image').style.opacity = "0";
            }
            aperture_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle> <a href="https://github.com/hasibzunair/thyroid-nodule-sc">Thyroid nodule segmentation from Ultrasound (US) images</a></papertitle></a><br>
                Authors: <strong>Hasib Zunair</strong>, Tajwar Abrar Aleef, Aimon Rahman and Labib Chowdhury<br>
                <a href="https://tn-scui2020.grand-challenge.org/"><em>MICCAI TN-SCUI Challenge</em></a>, 2020
                <br>
            <p>In this work, several state-of-the-art image segmentation techniques were explored for optimizing 
              Thyroid Nodule segmentation from Ultrasound images. This inlcuded supervised learning, transfer learning, 
              and generative adversarial learning.
            </p>
          </td>
        </tr>
        </tbody></table>

        <hr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Service</heading>
            <p></p>
          </td>
        </tr>
      </table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="comp6771.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://github.com/myconcordia/COMP478"> Lab Demonstrator, COMP 6771: Image Processing, Winter 2022</a>
              <br>
              <a href="https://users.encs.concordia.ca/~gregb/home/comp333-f2021.html"> Lab Demonstrator, COMP 333: Intro to Data Analytics, Fall 2021</a>
              <br>
              <a href="https://github.com/myconcordia/COMP478"> Lab Demonstrator, COMP 6771: Image Processing, Winter 2021</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="ericsson_rs.png"></td>
            <td width="75%" valign="center">
              <papertitle>Trainer, Applied AI & ML Upskill Program 2.0, Ericsson Canada</papertitle><br>
              <p>
                Presenting tutorials to Ericsson employees relevant to the projects as well as  
                suggesting relevant software tools for the projects. Also support project implementations 
                and ensure correctness of project approaches and results.
              </p>
              <a href="https://www.concordia.ca/news/stories/2021/11/18/concordia-and-ericsson-canada-team-up-to-integrate-and-enhance-applied-ai-research-and-development.html">Article</a>
              / <a href="https://github.com/hasibzunair/ds-tutorials">Tutorials</a>
            </td>
          </tr>
          

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="ieee_ras.jpg" alt="ras">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/hasibzunair/whats-image-classifcation-really"> Student Instructor, Image Classification with Python and Keras, Fall 2019</a>
              <br>
              <a href="https://github.com/hasibzunair/ieee19-py"> Student Instructor, Introduction to Python Programming, Winter 2019</a>
              <br>
              <a href="https://github.com/hasibzunair/ieee18-cv"> Student Instructor, Image Processing and Computer Vision, Fall 2018</a>
            </td>
          </tr>
          
        </tbody></table>
    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      </font>
        </p>
        <p align="right">
          <font size="2">
          Template stolen from <a href="https://jonbarron.info/">Jon Barron</a>. Thanks for dropping by.<br>
          Last updated February 2022.
          </font>
        </p>

    </td>
    </tr>
  </table>
  </body>
</html>
